import asyncio
import hashlib
import html
import json
import time
from typing import Dict, List, Optional

import aiohttp
import astrbot.api.message_components as Comp
from aiohttp import web
from aiohttp.web import Request, Response
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.star import Context, Star, register


@register(
    "media_webhook",
    "Assistant", 
    "åª’ä½“é€šçŸ¥ Webhook æ’ä»¶",
    "2.0.0",
    "https://github.com/example/astrbot_plugin_media_webhook",
)
class MediaWebhookPlugin(Star):
    """åª’ä½“é€šçŸ¥ Webhook æ’ä»¶"""

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        
        # æ ¸å¿ƒé…ç½®
        self.webhook_port = config.get("webhook_port", 60071)
        self.group_id = config.get("group_id", "")
        self.platform_name = config.get("platform_name", "aiocqhttp")
        self.batch_min_size = config.get("batch_min_size", 3)
        self.batch_interval_seconds = config.get("batch_interval_seconds", 300)
        self.cache_ttl_seconds = config.get("cache_ttl_seconds", 300)

        # API é…ç½®
        self.tmdb_api_key = config.get("tmdb_api_key", "")
        self.fanart_api_key = config.get("fanart_api_key", "")
        self.tmdb_base_url = "https://api.themoviedb.org/3"
        self.fanart_base_url = "https://webservice.fanart.tv/v3"
        
        # æ¶ˆæ¯é˜Ÿåˆ—å’Œç¼“å­˜
        self.message_queue: List[Dict] = []
        self.request_cache: Dict[str, float] = {}
        self.last_batch_time = time.time()
        
        # åª’ä½“ç±»å‹æ˜ å°„
        self.media_type_map = {
            "Movie": "ç”µå½±", "Series": "å‰§é›†", "Season": "å‰§å­£", "Episode": "å‰§é›†",
            "Album": "ä¸“è¾‘", "Song": "æ­Œæ›²", "Video": "è§†é¢‘"
        }
        
        self.type_emoji_map = {
            "Movie": "ğŸ¬", "Series": "ğŸ“º", "Season": "ğŸ“º", "Episode": "ğŸ“º",
            "Album": "ğŸµ", "Song": "ğŸ¶", "Video": "ğŸ“¹", "Default": "ğŸŒŸ"
        }
        
        # HTTP æœåŠ¡å™¨
        self.app = None
        self.runner = None
        self.site = None
        
        # å¯åŠ¨æœåŠ¡
        asyncio.create_task(self.start_webhook_server())
        asyncio.create_task(self.start_batch_processor())

    async def start_webhook_server(self):
        """å¯åŠ¨ Webhook æœåŠ¡å™¨"""
        try:
            self.app = web.Application()
            self.app.router.add_post("/media-webhook", self.handle_webhook)
            
            self.runner = web.AppRunner(self.app)
            await self.runner.setup()
            
            self.site = web.TCPSite(self.runner, "0.0.0.0", self.webhook_port)
            await self.site.start()
            
            logger.info(f"Media Webhook æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: {self.webhook_port}")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ Webhook æœåŠ¡å¤±è´¥: {e}")

    async def handle_webhook(self, request: Request) -> Response:
        """å¤„ç† Webhook è¯·æ±‚"""
        try:
            # è§£æè¯·æ±‚ä½“
            body_text = await request.text()
            if not body_text:
                return Response(text="è¯·æ±‚ä½“ä¸ºç©º", status=400)

            # è®°å½•è¯·æ±‚ä¿¡æ¯
            headers = dict(request.headers)
            logger.info(f"æ”¶åˆ° Webhook è¯·æ±‚:")
            logger.info(f"  User-Agent: {headers.get('user-agent', 'N/A')}")
            logger.info(f"  Content-Type: {headers.get('content-type', 'N/A')}")
            logger.info(f"  è¯·æ±‚ä½“é•¿åº¦: {len(body_text)} å­—ç¬¦")

            # å°è¯•è§£æ JSONï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä¿®å¤æˆ–æ£€æŸ¥å…¶ä»–æ ¼å¼
            try:
                raw_data = json.loads(body_text)
                is_text_template = False
                logger.info("æˆåŠŸè§£æä¸º JSON æ ¼å¼")
            except json.JSONDecodeError as e:
                logger.info(f"JSON è§£æå¤±è´¥: {e}")

                if not fixed_json:
                    # æ£€æŸ¥æ˜¯å¦ä¸º Ani-RSS æ–‡æœ¬æ¨¡æ¿
                    if self.is_ani_rss_text_template(body_text):
                        raw_data = {"text_template": body_text}
                        is_text_template = True
                        logger.info("æ£€æµ‹åˆ° ani-rss æ–‡æœ¬æ¨¡æ¿æ ¼å¼")
                    else:
                        logger.error("Webhook è¯·æ±‚ä½“è§£æå¤±è´¥: æ— æ•ˆçš„JSONæ ¼å¼ä¸”ä¸æ˜¯å·²çŸ¥çš„æ–‡æœ¬æ¨¡æ¿")
                        return Response(text="æ— æ•ˆçš„æ•°æ®æ ¼å¼", status=400)

            # æ£€æµ‹é€šçŸ¥æ¥æº
            if is_text_template:
                source = "ani-rss"
            else:
                source = self.detect_notification_source(raw_data, headers)

            # å¤„ç†ä¸åŒæ¥æºçš„æ•°æ®æ ¼å¼
            if source == "ani-rss":
                # Ani-RSS æ¶ˆæ¯ä¿æŒåŸå§‹æ ¼å¼ï¼Œä¸è¿›è¡Œæ•°æ®è½¬æ¢
                media_data = raw_data
                logger.info("æ£€æµ‹åˆ° ani-rss æ•°æ®ï¼Œä¿æŒåŸå§‹æ ¼å¼ç›´æ¥å‘é€")
            elif source == "emby":
                media_data = self.convert_emby_to_media_data(raw_data)
                logger.info("æ£€æµ‹åˆ° Emby æ•°æ®ï¼Œå·²è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼")
            elif source in ["jellyfin", "plex"]:
                # Jellyfin å’Œ Plex ä½¿ç”¨é€šç”¨çš„åª’ä½“æ•°æ®å¤„ç†
                media_data = self.convert_generic_media_data(raw_data)
                logger.info(f"æ£€æµ‹åˆ° {source.title()} æ•°æ®ï¼Œå·²è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼")
            else:
                media_data = raw_data

            # æ£€æŸ¥é‡å¤è¯·æ±‚
            if self.is_duplicate_request(media_data):
                logger.info("æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå¿½ç•¥")
                return Response(text="é‡å¤è¯·æ±‚", status=200)

            # ä½¿ç”¨å¤–éƒ¨ API ä¸°å¯Œæ•°æ®ï¼ˆé™¤äº† Ani-RSSï¼‰
            if source != "ani-rss":
                media_data = await self.enrich_media_data_with_external_apis(media_data)

            # æ·»åŠ åˆ°é˜Ÿåˆ—
            await self.add_to_queue(media_data, source)
            return Response(text="æ¶ˆæ¯å·²åŠ å…¥é˜Ÿåˆ—", status=200)

        except Exception as e:
            logger.error(f"Webhook å¤„ç†å‡ºé”™: {e}")
            return Response(text="å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯", status=500)

    def is_ani_rss_text_template(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º ani-rss æ–‡æœ¬æ¨¡æ¿"""
        # æ£€æŸ¥ ani-rss æ–‡æœ¬æ¨¡æ¿çš„ç‰¹å¾
        ani_rss_template_patterns = [
            "${emoji}", "${action}", "${title}", "${score}", "${tmdburl}",
            "${themoviedbName}", "${bgmUrl}", "${season}", "${episode}",
            "${subgroup}", "${currentEpisodeNumber}", "${totalEpisodeNumber}",
            "${year}", "${month}", "${date}", "${text}", "${downloadPath}",
            "${episodeTitle}"
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªæ¨¡æ¿å˜é‡
        for pattern in ani_rss_template_patterns:
            if pattern in text:
                return True
        return False

    def detect_notification_source(self, data: Dict, headers: Dict) -> str:
        """æ£€æµ‹é€šçŸ¥æ¥æº"""
        # æ£€æŸ¥ User-Agent ä¸­çš„ç‰¹å¾
        user_agent = headers.get("user-agent", "").lower()

        # ä¼˜å…ˆæ£€æŸ¥ User-Agent
        if "emby server" in user_agent:
            return "emby"
        elif "jellyfin" in user_agent:
            return "jellyfin"
        elif "plex" in user_agent:
            return "plex"

        # æ£€æŸ¥æ•°æ®ç»“æ„ç‰¹å¾
        if "Item" in data and "Server" in data:
            return "emby"
        elif "ItemType" in data or "SeriesName" in data:
            return "jellyfin"
        elif "Metadata" in data or "Player" in data:
            return "plex"

        return "unknown"

    def convert_emby_to_media_data(self, data: Dict) -> Dict:
        """å°† Emby æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†åª’ä½“æ•°æ®æ ¼å¼"""
        try:
            item = data.get("Item", {})

            # æå–åŸºæœ¬ä¿¡æ¯
            item_type = item.get("Type", "Unknown")
            item_name = item.get("Name", "")

            # å¤„ç†å‰§é›†ä¿¡æ¯
            series_name = ""
            season_number = ""
            episode_number = ""

            if item_type == "Episode":
                series_name = item.get("SeriesName", "")
                season_number = item.get("ParentIndexNumber", "")
                episode_number = item.get("IndexNumber", "")
            elif item_type == "Season":
                series_name = item.get("SeriesName", "")
                season_number = item.get("IndexNumber", "")
            elif item_type == "Series":
                series_name = item_name

            # æå–å…¶ä»–ä¿¡æ¯
            year = item.get("ProductionYear", "")
            overview = item.get("Overview", "")
            runtime_ticks = item.get("RunTimeTicks", 0)
            runtime = f"{runtime_ticks // 600000000}åˆ†é’Ÿ" if runtime_ticks > 0 else ""

            return {
                "item_type": item_type,
                "series_name": series_name,
                "item_name": item_name,
                "season_number": str(season_number) if season_number else "",
                "episode_number": str(episode_number) if episode_number else "",
                "year": str(year) if year else "",
                "overview": overview,
                "runtime": runtime,
                "image_url": ""
            }

        except Exception as e:
            logger.error(f"è½¬æ¢ Emby æ•°æ®å¤±è´¥: {e}")
            return {}

    def convert_generic_media_data(self, data: Dict) -> Dict:
        """å°†é€šç”¨åª’ä½“æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼ˆé€‚ç”¨äº Jellyfinã€Plex ç­‰ï¼‰"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            item_type = data.get("ItemType") or data.get("Type") or data.get("item_type", "Episode")

            # å¤„ç†å‰§é›†åç§°
            series_name = (
                data.get("SeriesName") or
                data.get("series_name") or
                data.get("Name") or
                data.get("name", "")
            )

            # å¤„ç†é›†åç§°
            item_name = (
                data.get("Name") or
                data.get("name") or
                data.get("ItemName") or
                data.get("item_name", "")
            )

            # å¤„ç†å­£é›†å·
            season_number = str(data.get("SeasonNumber") or data.get("season_number", ""))
            episode_number = str(data.get("EpisodeNumber") or data.get("episode_number", ""))

            # å¤„ç†å¹´ä»½
            year = str(data.get("Year") or data.get("year") or data.get("ProductionYear", ""))

            # å¤„ç†ç®€ä»‹
            overview = data.get("Overview") or data.get("overview") or data.get("Description", "")

            # å¤„ç†æ—¶é•¿
            runtime = data.get("Runtime") or data.get("runtime", "")
            if not runtime and data.get("RunTimeTicks"):
                runtime_ticks = data.get("RunTimeTicks", 0)
                runtime = f"{runtime_ticks // 600000000}åˆ†é’Ÿ" if runtime_ticks > 0 else ""

            return {
                "item_type": item_type,
                "series_name": series_name,
                "item_name": item_name,
                "season_number": season_number,
                "episode_number": episode_number,
                "year": year,
                "overview": overview,
                "runtime": runtime,
                "image_url": data.get("image_url", "")
            }

        except Exception as e:
            logger.error(f"è½¬æ¢é€šç”¨åª’ä½“æ•°æ®å¤±è´¥: {e}")
            return {}

    def is_duplicate_request(self, media_data: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚ - ä½¿ç”¨å“ˆå¸Œæ ¡éªŒï¼Œæ’é™¤å›¾ç‰‡ä»¥ä¿æŒæ›´é«˜å‡†ç¡®ç‡"""
        request_hash = self.calculate_request_hash(media_data)
        if not request_hash:
            return False

        current_time = time.time()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self.cleanup_expired_cache(current_time)

        # æ£€æŸ¥æ˜¯å¦é‡å¤
        if request_hash in self.request_cache:
            cached_time = self.request_cache[request_hash]
            logger.debug(f"æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå“ˆå¸Œ: {request_hash[:8]}..., ç¼“å­˜æ—¶é—´: {cached_time}")
            return True

        # ç¼“å­˜æ–°è¯·æ±‚
        self.request_cache[request_hash] = current_time + self.cache_ttl_seconds
        logger.debug(f"ç¼“å­˜æ–°è¯·æ±‚ï¼Œå“ˆå¸Œ: {request_hash[:8]}..., è¿‡æœŸæ—¶é—´: {current_time + self.cache_ttl_seconds}")
        return False

    def calculate_request_hash(self, media_data: Dict) -> str:
        """è®¡ç®—è¯·æ±‚å“ˆå¸Œå€¼ - æ’é™¤å›¾ç‰‡å’Œä¸ç¨³å®šå­—æ®µä»¥æé«˜å‡†ç¡®ç‡"""
        try:
            # æ ¹æ®æ•°æ®æ¥æºé€‰æ‹©ä¸åŒçš„å“ˆå¸Œç­–ç•¥
            if self.is_ani_rss_data(media_data):
                return self.calculate_ani_rss_hash(media_data)
            else:
                return self.calculate_standard_hash(media_data)
        except Exception as e:
            logger.error(f"è®¡ç®—è¯·æ±‚å“ˆå¸Œå¤±è´¥: {e}")
            return ""

    def is_ani_rss_data(self, media_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸º Ani-RSS æ•°æ®"""
        return "meassage" in media_data or "text_template" in media_data

    def calculate_ani_rss_hash(self, media_data: Dict) -> str:
        """è®¡ç®— Ani-RSS æ•°æ®çš„å“ˆå¸Œå€¼"""
        # å¯¹äº Ani-RSSï¼Œæå–å…³é”®ä¿¡æ¯è¿›è¡Œå“ˆå¸Œ
        if "meassage" in media_data:
            messages = media_data.get("meassage", [])
            text_content = ""
            for msg in messages:
                if isinstance(msg, dict) and msg.get("type") == "text":
                    text_data = msg.get("data", {})
                    text_content = text_data.get("text", "")
                    break

            # ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
            hash_data = {
                "content_hash": hashlib.md5(text_content.encode()).hexdigest()[:16],
                "data_type": "ani_rss_message"
            }
        elif "text_template" in media_data:
            template = media_data.get("text_template", "")
            hash_data = {
                "content_hash": hashlib.md5(template.encode()).hexdigest()[:16],
                "data_type": "ani_rss_template"
            }
        else:
            hash_data = {"data_type": "ani_rss_unknown"}

        hash_string = json.dumps(hash_data, sort_keys=True)
        return hashlib.sha256(hash_string.encode()).hexdigest()

    def calculate_standard_hash(self, media_data: Dict) -> str:
        """è®¡ç®—æ ‡å‡†åª’ä½“æ•°æ®çš„å“ˆå¸Œå€¼"""
        # æ’é™¤ä¸ç¨³å®šå­—æ®µ
        stable_fields = {
            k: v for k, v in media_data.items()
            if k not in ["image_url", "timestamp", "runtime_ticks"]
        }
        hash_string = json.dumps(stable_fields, sort_keys=True)
        return hashlib.sha256(hash_string.encode()).hexdigest()

    def cleanup_expired_cache(self, current_time: float):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        expired_keys = [
            key for key, expire_time in self.request_cache.items()
            if current_time > expire_time
        ]
        for key in expired_keys:
            del self.request_cache[key]

        if expired_keys:
            logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")

    def extract_ani_rss_content(self, data: Dict) -> Dict:
        """æå– Ani-RSS çš„å†…å®¹ï¼ˆåŒ…æ‹¬å›¾ç‰‡å’Œæ–‡æœ¬ï¼‰"""
        try:
            result = {
                "text": "",
                "image_url": ""
            }

            # æ£€æŸ¥æ˜¯å¦ä¸º Ani-RSS çœŸå®æ¶ˆæ¯æ ¼å¼
            if "meassage" in data:
                messages = data.get("meassage", [])
                for msg in messages:
                    if isinstance(msg, dict):
                        msg_type = msg.get("type", "")
                        msg_data = msg.get("data", {})

                        if msg_type == "text":
                            result["text"] = msg_data.get("text", "")
                        elif msg_type == "image":
                            result["image_url"] = msg_data.get("url", "")

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ¨¡æ¿æ ¼å¼
            elif "text_template" in data:
                result["text"] = data.get("text_template", "")

            return result

        except Exception as e:
            logger.error(f"æå– Ani-RSS å†…å®¹å¤±è´¥: {e}")
            return {"text": "", "image_url": ""}

    async def add_to_queue(self, media_data: Dict, source: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—"""
        try:
            # å¯¹äº Ani-RSSï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œä¸è¿›è¡Œè½¬æ¢
            if source == "ani-rss":
                ani_rss_content = self.extract_ani_rss_content(media_data)
                image_url = ani_rss_content.get("image_url", "")
                message_text = self.generate_ani_rss_raw_message(media_data)
            else:
                image_url = media_data.get("image_url", "")
                message_text = self.generate_message_text(media_data)

            message_payload = {
                "image_url": image_url,
                "message_text": message_text,
                "timestamp": time.time(),
                "source": source,
            }

            self.message_queue.append(message_payload)

            item_type = media_data.get('item_type', 'Unknown') if source != "ani-rss" else "Ani-RSS"
            logger.info(f"æ–° {item_type} é€šçŸ¥å·²åŠ å…¥é˜Ÿåˆ— [æ¥æº: {source}] {'(å«å›¾ç‰‡)' if image_url else '(æ— å›¾ç‰‡)'}")

        except Exception as e:
            logger.error(f"æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—å¤±è´¥: {e}")

    def generate_ani_rss_raw_message(self, data: Dict) -> str:
        """ä¸º Ani-RSS ç”ŸæˆåŸå§‹æ ¼å¼æ¶ˆæ¯ï¼ˆä»…è¿”å›æ–‡æœ¬éƒ¨åˆ†ï¼‰"""
        content = self.extract_ani_rss_content(data)
        return content["text"]

    def generate_title_by_type(self, item_type: str, cn_type: str, emoji: str, action: str, data: Dict) -> str:
        """æ ¹æ®åª’ä½“ç±»å‹ç”Ÿæˆåˆé€‚çš„æ ‡é¢˜"""
        if item_type == "Movie":
            return f"{emoji} æ–°ç”µå½±{action}"
        elif item_type in ["Series", "Season"]:
            return f"{emoji} å‰§é›†{action}"
        elif item_type == "Episode":
            # å¯¹äºå‰§é›†ï¼Œæ˜¾ç¤ºæ›´å…·ä½“çš„ä¿¡æ¯
            season_num = data.get("season_number", "")
            episode_num = data.get("episode_number", "")
            if season_num and episode_num:
                return f"{emoji} æ–°å‰§é›†{action}"
            else:
                return f"{emoji} å‰§é›†{action}"
        elif item_type == "Album":
            return f"{emoji} æ–°ä¸“è¾‘{action}"
        elif item_type == "Song":
            return f"{emoji} æ–°æ­Œæ›²{action}"
        elif item_type == "Video":
            return f"{emoji} æ–°è§†é¢‘{action}"
        elif item_type in ["Audio", "AudioBook"]:
            return f"{emoji} æ–°éŸ³é¢‘{action}"
        elif item_type == "Book":
            return f"{emoji} æ–°å›¾ä¹¦{action}"
        else:
            # é»˜è®¤æ ¼å¼
            return f"{emoji} æ–°{cn_type}{action}"

    def get_first_paragraph(self, text: str) -> str:
        """è·å–æ–‡æœ¬çš„ç¬¬ä¸€æ®µ"""
        if not text:
            return ""

        # æŒ‰å¥å·åˆ†å‰²
        sentences = text.split('ã€‚')
        if len(sentences) > 1 and sentences[0]:
            first_sentence = sentences[0].strip() + 'ã€‚'
            # é™åˆ¶é•¿åº¦
            if len(first_sentence) > 100:
                return first_sentence[:97] + "..."
            return first_sentence

        # æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
        lines = text.split('\n')
        first_line = lines[0].strip()
        if first_line:
            # é™åˆ¶é•¿åº¦
            if len(first_line) > 100:
                return first_line[:97] + "..."
            return first_line

        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œç›´æ¥æˆªå–å‰100ä¸ªå­—ç¬¦
        if len(text) > 100:
            return text[:97] + "..."
        return text.strip()

    async def enrich_media_data_with_external_apis(self, media_data: Dict) -> Dict:
        """ä½¿ç”¨å¤–éƒ¨ API ä¸°å¯Œåª’ä½“æ•°æ®ï¼ˆTMDB â†’ Fanart.tv â†’ åŸå§‹æ•°æ®ï¼‰"""
        try:
            # å¦‚æœæ²¡æœ‰ API å¯†é’¥ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
            if not self.tmdb_api_key:
                logger.debug("æœªé…ç½® TMDB API å¯†é’¥ï¼Œè·³è¿‡æ•°æ®ä¸°å¯Œ")
                return media_data

            # å°è¯•ä» TMDB è·å–æ•°æ®
            tmdb_data = await self.get_tmdb_data(media_data)
            if tmdb_data:
                # åˆå¹¶ TMDB æ•°æ®
                enriched_data = self.merge_tmdb_data(media_data, tmdb_data)

                # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œå°è¯•ä» Fanart.tv è·å–
                if not enriched_data.get("image_url") and self.fanart_api_key:
                    fanart_image = await self.get_fanart_image(enriched_data, tmdb_data)
                    if fanart_image:
                        enriched_data["image_url"] = fanart_image

                return enriched_data

            return media_data

        except Exception as e:
            logger.error(f"ä¸°å¯Œåª’ä½“æ•°æ®å¤±è´¥: {e}")
            return media_data

    async def get_tmdb_data(self, media_data: Dict) -> Dict:
        """ä» TMDB è·å–åª’ä½“æ•°æ®"""
        try:
            series_name = media_data.get("series_name", "")
            year = media_data.get("year", "")

            if not series_name:
                return {}

            # æœç´¢ç”µè§†å‰§
            search_url = f"{self.tmdb_base_url}/search/tv"
            params = {
                "api_key": self.tmdb_api_key,
                "query": series_name,
                "language": "zh-CN"
            }

            if year:
                params["first_air_date_year"] = year

            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = data.get("results", [])

                        if results:
                            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…ç»“æœ
                            return results[0]

            return {}

        except Exception as e:
            logger.error(f"è·å– TMDB æ•°æ®å¤±è´¥: {e}")
            return {}

    def merge_tmdb_data(self, original_data: Dict, tmdb_data: Dict) -> Dict:
        """åˆå¹¶ TMDB æ•°æ®åˆ°åŸå§‹æ•°æ®"""
        try:
            enriched_data = original_data.copy()

            # æ›´æ–°å‰§æƒ…ç®€ä»‹ï¼ˆå¦‚æœåŸå§‹æ•°æ®æ²¡æœ‰ï¼‰
            if not enriched_data.get("overview") and tmdb_data.get("overview"):
                enriched_data["overview"] = tmdb_data["overview"]

            # æ›´æ–°å¹´ä»½ï¼ˆå¦‚æœåŸå§‹æ•°æ®æ²¡æœ‰ï¼‰
            if not enriched_data.get("year") and tmdb_data.get("first_air_date"):
                first_air_date = tmdb_data["first_air_date"]
                if first_air_date:
                    enriched_data["year"] = first_air_date.split("-")[0]

            # æ›´æ–°å›¾ç‰‡ï¼ˆå¦‚æœåŸå§‹æ•°æ®æ²¡æœ‰ï¼‰
            if not enriched_data.get("image_url") and tmdb_data.get("poster_path"):
                poster_path = tmdb_data["poster_path"]
                enriched_data["image_url"] = f"https://image.tmdb.org/t/p/w500{poster_path}"

            # æ·»åŠ  TMDB ID ç”¨äºåç»­ Fanart.tv æŸ¥è¯¢
            if tmdb_data.get("id"):
                enriched_data["tmdb_id"] = tmdb_data["id"]

            return enriched_data

        except Exception as e:
            logger.error(f"åˆå¹¶ TMDB æ•°æ®å¤±è´¥: {e}")
            return original_data

    async def get_fanart_image(self, media_data: Dict, tmdb_data: Dict) -> str:
        """ä» Fanart.tv è·å–å›¾ç‰‡"""
        try:
            tmdb_id = tmdb_data.get("id")
            if not tmdb_id:
                return ""

            fanart_url = f"{self.fanart_base_url}/tv/{tmdb_id}"
            params = {"api_key": self.fanart_api_key}

            async with aiohttp.ClientSession() as session:
                async with session.get(fanart_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()

                        # ä¼˜å…ˆé€‰æ‹© tvposterï¼Œç„¶åæ˜¯ tvbanner
                        if "tvposter" in data and data["tvposter"]:
                            return data["tvposter"][0]["url"]
                        elif "tvbanner" in data and data["tvbanner"]:
                            return data["tvbanner"][0]["url"]

            return ""

        except Exception as e:
            logger.error(f"è·å– Fanart.tv å›¾ç‰‡å¤±è´¥: {e}")
            return ""

    def generate_message_text(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯æ–‡æœ¬ï¼ˆç´§å‡‘æ’åˆ—ä¼˜åŒ–ï¼‰"""
        item_type = data.get("item_type", "")
        cn_type = self.media_type_map.get(item_type, item_type)
        emoji = self.type_emoji_map.get(item_type, self.type_emoji_map["Default"])

        # ç”Ÿæˆæ ‡é¢˜
        title = self.generate_title_by_type(item_type, cn_type, emoji, "ä¸Šçº¿", data)
        message_parts = [title]

        # ä¸»è¦ä¿¡æ¯ï¼ˆç´§å‡‘æ’åˆ—ï¼‰
        main_section = self.generate_main_section(data)
        if main_section:
            message_parts.append(main_section)

        # åªæ˜¾ç¤ºç¬¬ä¸€æ®µå‰§æƒ…ç®€ä»‹
        overview = data.get("overview", "")
        if overview:
            decoded_overview = html.unescape(overview)
            # åªå–ç¬¬ä¸€æ®µï¼ˆä»¥å¥å·ã€æ¢è¡Œç¬¦æˆ–é•¿åº¦ä¸ºç•Œï¼‰
            first_paragraph = self.get_first_paragraph(decoded_overview)
            if first_paragraph:
                if item_type == "Movie":
                    message_parts.append(f"å‰§æƒ…ç®€ä»‹: {first_paragraph}")
                elif item_type in ["Series", "Season", "Episode"]:
                    message_parts.append(f"å‰§æƒ…ç®€ä»‹: {first_paragraph}")
                elif item_type == "Album":
                    message_parts.append(f"ä¸“è¾‘ä»‹ç»: {first_paragraph}")
                elif item_type == "Song":
                    message_parts.append(f"æ­Œæ›²ä»‹ç»: {first_paragraph}")
                elif item_type == "Book":
                    message_parts.append(f"å†…å®¹ç®€ä»‹: {first_paragraph}")
                else:
                    message_parts.append(f"å†…å®¹ç®€ä»‹: {first_paragraph}")

        # æ—¶é•¿ä¿¡æ¯
        runtime = data.get("runtime", "")
        if runtime:
            if item_type == "Movie":
                message_parts.append(f"ç‰‡é•¿: {runtime}")
            elif item_type in ["Episode", "Video"]:
                message_parts.append(f"æ—¶é•¿: {runtime}")
            elif item_type == "Song":
                message_parts.append(f"æ—¶é•¿: {runtime}")
            else:
                message_parts.append(f"æ—¶é•¿: {runtime}")

        # æ•°æ®æ¥æºæ ‡è®°
        if data.get("tmdb_enriched"):
            message_parts.append("âœ¨ æ•°æ®æ¥æº: TMDB")
        elif data.get("bgm_enriched"):
            message_parts.append("âœ¨ æ•°æ®æ¥æº: BGM.TV")

        return "\n".join(message_parts)

    def generate_main_section(self, data: Dict) -> str:
        """ç”Ÿæˆä¸»è¦ä¿¡æ¯éƒ¨åˆ†"""
        sections = []
        
        # å‰§é›†åç§°
        if data.get("series_name"):
            name_part = data["series_name"]
            if data.get("year"):
                name_part += f" ({data['year']})"
            sections.append(f"å‰§é›†åç§°: {name_part}")
        
        # æ ¹æ®ç±»å‹ç”Ÿæˆä¸åŒä¿¡æ¯
        item_type = data.get("item_type", "")
        
        if item_type == "Episode":
            # é›†å·
            season_num = data.get("season_number", "")
            episode_num = data.get("episode_number", "")
            if season_num and episode_num:
                season_str = str(season_num).zfill(2)
                episode_str = str(episode_num).zfill(2)
                sections.append(f"é›†å·: S{season_str}E{episode_str}")
            
            # é›†åç§°
            if data.get("item_name"):
                sections.append(f"é›†åç§°: {data['item_name']}")
                
        elif item_type == "Season":
            # å­£åç§°
            if data.get("item_name"):
                sections.append(f"å­£åç§°: {data['item_name']}")
            if data.get("season_number"):
                sections.append(f"å­£å·: {data['season_number']}")
                
        else:
            # å…¶ä»–ç±»å‹
            if data.get("item_name"):
                sections.append(f"åç§°: {data['item_name']}")
            if data.get("year") and not data.get("series_name"):
                sections.append(f"å¹´ä»½: {data['year']}")
        
        return "\n".join(sections)

    async def start_batch_processor(self):
        """å¯åŠ¨æ‰¹é‡å¤„ç†å™¨"""
        logger.info("å¯åŠ¨æ‰¹é‡å¤„ç†å™¨")
        while True:
            try:
                await asyncio.sleep(self.batch_interval_seconds)
                await self.process_message_queue()
            except Exception as e:
                logger.error(f"æ‰¹é‡å¤„ç†å™¨å‡ºé”™: {e}")
                await asyncio.sleep(10)

    async def process_message_queue(self):
        """å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—"""
        if not self.message_queue:
            return
        
        if not self.group_id:
            logger.warning("æœªé…ç½®ç¾¤ç»„IDï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return
        
        messages = self.message_queue.copy()
        self.message_queue.clear()
        
        logger.info(f"ä»é˜Ÿåˆ—ä¸­å–å‡º {len(messages)} æ¡å¾…å‘æ¶ˆæ¯")
        
        try:
            # æ ¹æ®æ¶ˆæ¯æ•°é‡å’Œå¹³å°èƒ½åŠ›é€‰æ‹©å‘é€æ–¹å¼
            if len(messages) >= self.batch_min_size and self.platform_name.lower() == "aiocqhttp":
                await self.send_batch_messages(messages)
            else:
                await self.send_individual_messages(messages)
                
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
        finally:
            self.last_batch_time = time.time()

    async def send_batch_messages(self, messages: List[Dict]):
        """å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼ˆä»… aiocqhttpï¼‰"""
        group_id = str(self.group_id).replace(":", "_")
        unified_msg_origin = f"{self.platform_name}:GroupMessage:{group_id}"

        logger.info(f"å‘é€åˆå¹¶è½¬å‘: {len(messages)} æ¡æ¶ˆæ¯")

        try:
            # æ„å»ºåˆå¹¶è½¬å‘èŠ‚ç‚¹
            forward_nodes = []
            for msg in messages:
                content_list = []

                # æ·»åŠ å›¾ç‰‡
                if msg.get("image_url"):
                    content_list.append(Comp.Image.fromURL(msg["image_url"]))

                # æ·»åŠ æ–‡æœ¬
                content_list.append(Comp.Plain(msg["message_text"]))

                # åˆ›å»ºæ¶ˆæ¯é“¾
                message_chain = MessageChain(content_list)

                # åˆ›å»ºè½¬å‘èŠ‚ç‚¹
                node = Comp.Node(
                    uin="2659908767",  # å¯é…ç½®
                    name="åª’ä½“é€šçŸ¥",
                    content=content_list
                )
                forward_nodes.append(node)

            # åˆ›å»ºåˆå¹¶è½¬å‘æ¶ˆæ¯é“¾
            forward_chain = MessageChain(forward_nodes)
            await self.context.send_message(unified_msg_origin, forward_chain)
            logger.info(f"âœ… æˆåŠŸå‘é€ {len(forward_nodes)} æ¡åˆå¹¶è½¬å‘æ¶ˆæ¯")

        except Exception as e:
            logger.error(f"å‘é€åˆå¹¶è½¬å‘å¤±è´¥: {e}")
            # å›é€€åˆ°å•ç‹¬å‘é€
            await self.send_individual_messages(messages)

    async def send_individual_messages(self, messages: List[Dict]):
        """å‘é€å•ç‹¬æ¶ˆæ¯"""
        group_id = str(self.group_id).replace(":", "_")
        unified_msg_origin = f"{self.platform_name}:GroupMessage:{group_id}"

        logger.info(f"å‘é€å•ç‹¬æ¶ˆæ¯: {len(messages)} æ¡æ¶ˆæ¯")

        for i, msg in enumerate(messages, 1):
            try:
                content_list = []

                # æ·»åŠ å›¾ç‰‡
                if msg.get("image_url"):
                    content_list.append(Comp.Image.fromURL(msg["image_url"]))

                # æ·»åŠ æ–‡æœ¬
                content_list.append(Comp.Plain(msg["message_text"]))

                # åˆ›å»ºæ¶ˆæ¯é“¾
                message_chain = MessageChain(content_list)

                await self.context.send_message(unified_msg_origin, message_chain)
                logger.debug(f"âœ… æ¶ˆæ¯ {i}/{len(messages)} å‘é€æˆåŠŸ")

                # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
                if i < len(messages):
                    await asyncio.sleep(0.5)

            except Exception as e:
                logger.error(f"âŒ æ¶ˆæ¯ {i} å‘é€å¤±è´¥: {e}")

    @filter.command("webhook status")
    async def webhook_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ Webhook çŠ¶æ€"""
        queue_size = len(self.message_queue)
        cache_size = len(self.request_cache)
        
        status_text = f"""ğŸ“Š Webhook çŠ¶æ€

ğŸŒ æœåŠ¡çŠ¶æ€: {'è¿è¡Œä¸­' if self.site else 'æœªå¯åŠ¨'}
ğŸ“¡ ç›‘å¬ç«¯å£: {self.webhook_port}
ğŸ“‹ é˜Ÿåˆ—æ¶ˆæ¯: {queue_size} æ¡
ğŸ—‚ï¸ ç¼“å­˜æ¡ç›®: {cache_size} æ¡
âš™ï¸ æ‰¹é‡é˜ˆå€¼: {self.batch_min_size} æ¡
â±ï¸ æ‰¹é‡é—´éš”: {self.batch_interval_seconds} ç§’
ğŸ¯ ç›®æ ‡ç¾¤ç»„: {self.group_id or 'æœªé…ç½®'}
ğŸ¤– åè®®å¹³å°: {self.platform_name}"""

        yield event.plain_result(status_text)

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        try:
            if self.site:
                await self.site.stop()
            if self.runner:
                await self.runner.cleanup()
            logger.info("Media Webhook æœåŠ¡å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ Webhook æœåŠ¡æ—¶å‡ºé”™: {e}")
