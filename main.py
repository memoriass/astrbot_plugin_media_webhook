import asyncio
import hashlib
import html
import json
import random
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

import astrbot.api.message_components as Comp
import aiohttp
from aiohttp import web
from aiohttp.web import Request, Response
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.star import Context, Star, register


class MediaSource(Enum):
    """åª’ä½“æ¥æºæšä¸¾"""
    JELLYFIN = "jellyfin"
    EMBY = "emby"
    PLEX = "plex"
    ANI_RSS = "ani-rss"
    SONARR = "sonarr"
    RADARR = "radarr"
    DEFAULT = "default"


class DataSource(Enum):
    """æ•°æ®æ¥æºæšä¸¾"""
    TMDB = "tmdb"
    BGM_TV = "bgm"
    ORIGINAL = "original"


@dataclass
class MediaData:
    """åª’ä½“æ•°æ®ç»“æ„"""
    item_type: str = "Episode"
    series_name: str = ""
    item_name: str = ""
    season_number: str = ""
    episode_number: str = ""
    overview: str = ""
    runtime: str = ""
    year: str = ""
    image_url: str = ""
    event_type: str = ""
    data_source: Optional[DataSource] = None

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = {
            "item_type": self.item_type,
            "series_name": self.series_name,
            "item_name": self.item_name,
            "season_number": self.season_number,
            "episode_number": self.episode_number,
            "overview": self.overview,
            "runtime": self.runtime,
            "year": self.year,
            "event_type": self.event_type,
        }
        if self.image_url:
            result["image_url"] = self.image_url
        if self.data_source:
            result[f"{self.data_source.value}_enriched"] = True
        return result


@register(
    "media_webhook",
    "Assistant",
    "åª’ä½“é€šçŸ¥ Webhook æ’ä»¶",
    "1.0.0",
    "https://github.com/example/astrbot_plugin_media_webhook",
)
class MediaWebhookPlugin(Star):
    """åª’ä½“é€šçŸ¥ Webhook æ’ä»¶ä¸»ç±»"""

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config

        # HTTP æœåŠ¡å™¨ç›¸å…³
        self.app = None
        self.runner = None
        self.site = None

        # æ ¸å¿ƒé…ç½®
        self._init_core_config()

        # ç¼“å­˜å’Œé˜Ÿåˆ—
        self._init_cache_and_queue()

    def _init_core_config(self):
        """åˆå§‹åŒ–æ ¸å¿ƒé…ç½® - ä¼˜åŒ–é…ç½®è·å–æ€§èƒ½"""
        # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰é…ç½®ï¼Œé¿å…é‡å¤è°ƒç”¨ config.get()
        config = self.config
        self.webhook_port = config.get("webhook_port", 60071)
        self.webhook_path = config.get("webhook_path", "/media-webhook")
        self.group_id = config.get("group_id", "")
        self.platform_name = config.get("platform_name", "aiocqhttp")

        # æ‰¹é‡å¤„ç†é…ç½®
        self.batch_min_size = config.get("batch_min_size", 3)
        self.batch_interval_seconds = config.get("batch_interval_seconds", 300)
        self.cache_ttl_seconds = config.get("cache_ttl_seconds", 300)
        self.force_individual_send = config.get("force_individual_send", False)

        # æ˜¾ç¤ºé…ç½®
        self.show_platform_prefix = config.get("show_platform_prefix", True)
        self.show_source_info = config.get("show_source_info", True)

        # API é…ç½®
        self.tmdb_api_key = config.get("tmdb_api_key", "")
        self.tmdb_base_url = "https://api.themoviedb.org/3"
        self.bgm_base_url = "https://api.bgm.tv"

    def _init_cache_and_queue(self):
        """åˆå§‹åŒ–ç¼“å­˜å’Œé˜Ÿåˆ—"""
        self.message_queue: List[Dict] = []
        self.request_cache: Dict[str, float] = {}
        self.tmdb_cache: Dict[str, Dict] = {}
        self.bgm_cache: Dict[str, Dict] = {}
        self.last_batch_time = time.time()

        # é…ç½®ç¼“å­˜ï¼Œé¿å…é‡å¤è°ƒç”¨ config.get()
        self._config_cache: Dict[str, any] = {}

        # æ˜ å°„è¡¨
        self._init_mappings()

    def _get_config(self, key: str, default=None):
        """è·å–é…ç½®å€¼ï¼Œå¸¦ç¼“å­˜ä¼˜åŒ–"""
        if key not in self._config_cache:
            self._config_cache[key] = self.config.get(key, default)
        return self._config_cache[key]

    def _init_mappings(self):
        """åˆå§‹åŒ–æ˜ å°„è¡¨"""
        self.media_type_map = {
            "Movie": "ç”µå½±", "Series": "å‰§é›†", "Season": "å‰§å­£", "Episode": "å‰§é›†",
            "Album": "ä¸“è¾‘", "Song": "æ­Œæ›²", "Video": "è§†é¢‘", "Audio": "éŸ³é¢‘",
            "Book": "å›¾ä¹¦", "AudioBook": "æœ‰å£°ä¹¦",
        }

        self.type_emoji_map = {
            "Movie": "ğŸ¬", "Series": "ğŸ“º", "Season": "ğŸ“º", "Episode": "ğŸ“º",
            "Album": "ğŸµ", "Song": "ğŸ¶", "Video": "ğŸ“¹", "Audio": "ğŸ§",
            "Book": "ğŸ“š", "AudioBook": "ğŸ§", "Default": "ğŸŒŸ"
        }

        self.media_action_map = {
            "Movie": "ä¸Šæ˜ ", "Series": "æ›´æ–°", "Season": "å¼€æ’­", "Episode": "æ›´æ–°",
            "Album": "å‘å¸ƒ", "Song": "å‘å¸ƒ", "Video": "å‘å¸ƒ", "Audio": "å‘å¸ƒ",
            "Book": "ä¸Šæ¶", "AudioBook": "ä¸Šæ¶",
        }

        self.source_map = {
            MediaSource.JELLYFIN.value: "Jellyfin",
            MediaSource.EMBY.value: "Emby",
            MediaSource.PLEX.value: "Plex",
            MediaSource.SONARR.value: "Sonarr",
            MediaSource.RADARR.value: "Radarr",
            MediaSource.ANI_RSS.value: "Ani-RSS",
            MediaSource.DEFAULT.value: "åª’ä½“æœåŠ¡å™¨"
        }

        # å¹³å°å‰ç¼€æ˜ å°„
        self.platform_prefix_map = {
            "aiocqhttp": "ğŸ¤–",
            "telegram": "âœˆï¸",
            "gewechat": "ğŸ’¬",
            "qqofficial": "ğŸ¤–",
            "lark": "ğŸš€",
            "dingtalk": "ğŸ“±",
            "discord": "ğŸ®",
            "wecom": "ğŸ’¼",
            "default": "ğŸ“¢"
        }

        # éªŒè¯é…ç½®
        self.validate_config()

        # å¯åŠ¨HTTPæœåŠ¡å™¨å’Œå®šæ—¶ä»»åŠ¡
        asyncio.create_task(self.start_webhook_server())
        asyncio.create_task(self.start_batch_processor())

    def validate_config(self):
        """éªŒè¯é…ç½®å‚æ•° - ä¼˜åŒ–é…ç½®éªŒè¯é€»è¾‘"""
        # é…ç½®éªŒè¯è§„åˆ™
        validation_rules = [
            ("webhook_port", 60071, lambda x: isinstance(x, int) and 1 <= x <= 65535, "æ— æ•ˆçš„ç«¯å£å·"),
            ("batch_interval_seconds", 300, lambda x: isinstance(x, int) and x >= 10, "æ‰¹é‡å¤„ç†é—´éš”è¿‡çŸ­", 10),
            ("cache_ttl_seconds", 300, lambda x: isinstance(x, int) and x >= 60, "ç¼“å­˜TTLè¿‡çŸ­", 60),
            ("batch_min_size", 3, lambda x: isinstance(x, int) and x >= 1, "æ‰¹é‡å‘é€é˜ˆå€¼æ— æ•ˆ", 1),
        ]

        for rule in validation_rules:
            key, default, validator, error_msg = rule[:4]
            min_value = rule[4] if len(rule) > 4 else default

            value = self.config.get(key, default)
            if not validator(value):
                logger.warning(f"{error_msg}: {value}ï¼Œè®¾ç½®ä¸º {min_value}")
                self.config[key] = min_value
                # æ¸…é™¤ç¼“å­˜ä¸­çš„æ—§å€¼
                self._config_cache.pop(key, None)

    async def start_webhook_server(self):
        """å¯åŠ¨HTTP WebhookæœåŠ¡å™¨"""
        try:
            self.app = web.Application()
            self.app.router.add_post(
                self.webhook_path, self.handle_webhook
            )

            self.runner = web.AppRunner(self.app)
            await self.runner.setup()

            self.site = web.TCPSite(self.runner, "0.0.0.0", self.webhook_port)
            await self.site.start()

            logger.info(f"Media Webhook æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: {self.webhook_port}")
            logger.info(
                f"è®¿é—®åœ°å€: http://localhost:{self.webhook_port}{self.webhook_path}"
            )

        except OSError as e:
            error_msg = (
                f"ç«¯å£ {self.webhook_port} å·²è¢«å ç”¨ï¼Œè¯·æ›´æ¢ç«¯å£"
                if "Address already in use" in str(e) or "Only one usage" in str(e)
                else f"ç½‘ç»œé”™è¯¯: {e}"
            )
            logger.error(error_msg)
        except Exception as e:
            logger.error(f"å¯åŠ¨ Webhook æœåŠ¡å™¨å¤±è´¥: {e}")

    async def handle_webhook(self, request: Request) -> Response:
        """å¤„ç†Webhookè¯·æ±‚"""
        try:
            # è§£æè¯·æ±‚ä½“
            body_text = await request.text()
            if not body_text:
                return Response(text="è¯·æ±‚ä½“ä¸ºç©º", status=400)

            # è®°å½•è¯·æ±‚ä¿¡æ¯
            headers = dict(request.headers)
            logger.info(f"æ”¶åˆ° Webhook è¯·æ±‚:")
            logger.info(f"  User-Agent: {headers.get('user-agent', 'N/A')}")
            logger.info(f"  Content-Type: {headers.get('content-type', 'N/A')}")
            logger.info(f"  è¯·æ±‚ä½“é•¿åº¦: {len(body_text)} å­—ç¬¦")

            # å°è¯•è§£æ JSONï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä¿®å¤æˆ–æ£€æŸ¥å…¶ä»–æ ¼å¼
            try:
                raw_data = json.loads(body_text)
                is_text_template = False
                logger.info("æˆåŠŸè§£æä¸º JSON æ ¼å¼")
            except json.JSONDecodeError as e:
                logger.info(f"JSON è§£æå¤±è´¥: {e}")

                # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„ ani-rss JSON
                fixed_json = self.try_fix_ani_rss_json(body_text)
                if fixed_json:
                    try:
                        raw_data = json.loads(fixed_json)
                        is_text_template = False
                        logger.info("æˆåŠŸä¿®å¤å¹¶è§£æ ani-rss ä¸å®Œæ•´ JSON")
                    except json.JSONDecodeError:
                        fixed_json = None

                if not fixed_json:
                    # æ£€æŸ¥æ˜¯å¦ä¸º Ani-RSS æ–‡æœ¬æ¨¡æ¿
                    if self.is_ani_rss_text_template(body_text):
                        raw_data = {"text_template": body_text}
                        is_text_template = True
                        logger.info("æ£€æµ‹åˆ° ani-rss æ–‡æœ¬æ¨¡æ¿æ ¼å¼")
                    else:
                        logger.error("Webhook è¯·æ±‚ä½“è§£æå¤±è´¥: æ— æ•ˆçš„JSONæ ¼å¼ä¸”ä¸æ˜¯å·²çŸ¥çš„æ–‡æœ¬æ¨¡æ¿")
                        logger.error(f"å®Œæ•´è¯·æ±‚ä½“å†…å®¹:\n{body_text}")
                        # ä¿å­˜å¤±è´¥çš„è¯·æ±‚åˆ°æ–‡ä»¶ä»¥ä¾›åˆ†æ
                        import datetime
                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"failed_webhook_{timestamp}.txt"
                        with open(filename, 'w', encoding='utf-8') as f:
                            f.write(f"æ—¶é—´: {timestamp}\n")
                            f.write(f"User-Agent: {headers.get('user-agent', 'N/A')}\n")
                            f.write(f"Content-Type: {headers.get('content-type', 'N/A')}\n")
                            f.write(f"è¯·æ±‚ä½“:\n{body_text}")
                        logger.error(f"å¤±è´¥çš„è¯·æ±‚å·²ä¿å­˜åˆ°: {filename}")
                        return Response(text="æ— æ•ˆçš„æ•°æ®æ ¼å¼", status=400)

            # æ£€æµ‹é€šçŸ¥æ¥æº
            headers = dict(request.headers)
            if is_text_template:
                source = "ani-rss"
            else:
                source = self.detect_notification_source(raw_data, headers)

            # å¤„ç†ä¸åŒæ¥æºçš„æ•°æ®æ ¼å¼
            if source == "ani-rss":
                # Ani-RSS æ¶ˆæ¯ä¿æŒåŸå§‹æ ¼å¼ï¼Œä¸è¿›è¡Œæ•°æ®è½¬æ¢æˆ–ä¸°å¯Œ
                media_data = raw_data
                logger.info("æ£€æµ‹åˆ° ani-rss æ•°æ®ï¼Œä¿æŒåŸå§‹æ ¼å¼ç›´æ¥å‘é€")
            elif source == "emby":
                media_data = self.convert_emby_to_media_data(raw_data)
                logger.info("æ£€æµ‹åˆ° Emby æ•°æ®ï¼Œå·²è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼")

                # ä½¿ç”¨å¤–éƒ¨ API ä¸°å¯Œæ•°æ®ï¼ˆTMDB â†’ BGM.TV â†’ åŸå§‹æ•°æ®ï¼‰
                media_data = await self.enrich_media_data_with_external_apis(media_data)
            elif source in ["jellyfin", "plex"]:
                # Jellyfin å’Œ Plex ä½¿ç”¨é€šç”¨çš„åª’ä½“æ•°æ®å¤„ç†
                media_data = self.convert_generic_media_data(raw_data)
                logger.info(f"æ£€æµ‹åˆ° {source.title()} æ•°æ®ï¼Œå·²è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼")

                # ä½¿ç”¨å¤–éƒ¨ API ä¸°å¯Œæ•°æ®ï¼ˆTMDB â†’ BGM.TV â†’ åŸå§‹æ•°æ®ï¼‰
                media_data = await self.enrich_media_data_with_external_apis(media_data)
            else:
                media_data = raw_data

            # æ£€æŸ¥é‡å¤è¯·æ±‚
            if self._is_duplicate_request(media_data):
                logger.info("æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå¿½ç•¥")
                return Response(text="é‡å¤è¯·æ±‚", status=200)

            # æ·»åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            self._add_to_queue(media_data, source)
            return Response(text="æ¶ˆæ¯å·²åŠ å…¥é˜Ÿåˆ—", status=200)

        except json.JSONDecodeError:
            logger.error("Webhook è¯·æ±‚ä½“è§£æå¤±è´¥: æ— æ•ˆçš„JSONæ ¼å¼")
            return Response(text="æ— æ•ˆçš„JSONæ ¼å¼", status=400)
        except Exception as e:
            logger.error(f"Webhook å¤„ç†å‡ºé”™: {e}")
            return Response(text="å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯", status=500)

    def _is_duplicate_request(self, media_data: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚ - ä½¿ç”¨å“ˆå¸Œæ ¡éªŒï¼Œæ’é™¤å›¾ç‰‡ä»¥ä¿æŒæ›´é«˜å‡†ç¡®ç‡"""
        request_hash = self._calculate_request_hash(media_data)
        if not request_hash:
            return False

        current_time = time.time()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_expired_cache(current_time)

        # æ£€æŸ¥æ˜¯å¦é‡å¤
        if request_hash in self.request_cache:
            cached_time = self.request_cache[request_hash]
            logger.debug(f"æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå“ˆå¸Œ: {request_hash[:8]}..., ç¼“å­˜æ—¶é—´: {cached_time}")
            return True

        # ç¼“å­˜æ–°è¯·æ±‚
        cache_ttl = self.cache_ttl_seconds
        self.request_cache[request_hash] = current_time + cache_ttl
        logger.debug(f"ç¼“å­˜æ–°è¯·æ±‚ï¼Œå“ˆå¸Œ: {request_hash[:8]}..., è¿‡æœŸæ—¶é—´: {current_time + cache_ttl}")
        return False

    def _calculate_request_hash(self, media_data: Dict) -> Optional[str]:
        """è®¡ç®—è¯·æ±‚å“ˆå¸Œå€¼ - æ’é™¤å›¾ç‰‡å’Œä¸ç¨³å®šå­—æ®µä»¥æé«˜å‡†ç¡®ç‡"""
        try:
            # æ ¹æ®æ•°æ®æ¥æºé€‰æ‹©ä¸åŒçš„å“ˆå¸Œç­–ç•¥
            if self._is_ani_rss_data(media_data):
                return self._calculate_ani_rss_hash(media_data)
            else:
                return self._calculate_standard_hash(media_data)
        except Exception as e:
            logger.error(f"è®¡ç®—è¯·æ±‚å“ˆå¸Œå¤±è´¥: {e}")
            return None

    def _is_ani_rss_data(self, media_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸º Ani-RSS æ•°æ®"""
        return "meassage" in media_data or "text_template" in media_data

    def _calculate_ani_rss_hash(self, media_data: Dict) -> str:
        """è®¡ç®— Ani-RSS æ•°æ®çš„å“ˆå¸Œå€¼"""
        # å¯¹äº Ani-RSSï¼Œæå–å…³é”®ä¿¡æ¯è¿›è¡Œå“ˆå¸Œ
        if "meassage" in media_data:
            messages = media_data.get("meassage", [])
            text_content = ""
            for msg in messages:
                if isinstance(msg, dict) and msg.get("type") == "text":
                    text_data = msg.get("data", {})
                    text_content = text_data.get("text", "")
                    break

            # ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
            hash_data = {
                "content_hash": hashlib.md5(text_content.encode()).hexdigest()[:16],
                "data_type": "ani_rss_message"
            }
        elif "text_template" in media_data:
            template = media_data.get("text_template", "")
            hash_data = {
                "content_hash": hashlib.md5(template.encode()).hexdigest()[:16],
                "data_type": "ani_rss_template"
            }
        else:
            # å…¶ä»– Ani-RSS æ ¼å¼
            content_str = json.dumps(media_data, sort_keys=True)
            hash_data = {
                "content_hash": hashlib.md5(content_str.encode()).hexdigest()[:16],
                "data_type": "ani_rss_other"
            }

        hash_string = json.dumps(hash_data, sort_keys=True)
        return hashlib.sha256(hash_string.encode()).hexdigest()

    def _calculate_standard_hash(self, media_data: Dict) -> str:
        """è®¡ç®—æ ‡å‡†åª’ä½“æ•°æ®çš„å“ˆå¸Œå€¼ - æ’é™¤å›¾ç‰‡å’Œæ—¶é—´æˆ³ç­‰ä¸ç¨³å®šå­—æ®µ"""
        # æå–æ ¸å¿ƒæ ‡è¯†å­—æ®µï¼Œæ’é™¤å›¾ç‰‡URLã€æ—¶é—´æˆ³ç­‰ä¸ç¨³å®šå­—æ®µ
        hash_data = {
            "series_name": media_data.get("series_name", "").strip(),
            "item_name": media_data.get("item_name", "").strip(),
            "season_number": str(media_data.get("season_number", "")).strip(),
            "episode_number": str(media_data.get("episode_number", "")).strip(),
            "item_type": media_data.get("item_type", "").strip(),
            "year": str(media_data.get("year", "")).strip(),
        }

        # ç§»é™¤ç©ºå€¼ä»¥æé«˜åŒ¹é…å‡†ç¡®ç‡
        hash_data = {k: v for k, v in hash_data.items() if v}

        # å¦‚æœå…³é”®å­—æ®µéƒ½ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ•°æ®çš„éƒ¨åˆ†å†…å®¹
        if not hash_data:
            # æ’é™¤å›¾ç‰‡URLå’Œæ—¶é—´æˆ³ç­‰å­—æ®µ
            excluded_fields = {
                "image_url", "timestamp", "raw_message", "headers",
                "request_time", "processed_time", "cache_time"
            }
            filtered_data = {
                k: v for k, v in media_data.items()
                if k not in excluded_fields and not k.endswith("_url")
            }
            hash_data = {"fallback_content": str(filtered_data)}

        hash_string = json.dumps(hash_data, sort_keys=True, ensure_ascii=False)
        return hashlib.sha256(hash_string.encode()).hexdigest()

    def _cleanup_expired_cache(self, current_time: float):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        expired_keys = [
            key for key, expire_time in self.request_cache.items()
            if expire_time < current_time
        ]
        if expired_keys:
            logger.debug(f"æ¸…ç† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")
            for key in expired_keys:
                del self.request_cache[key]

    async def _add_to_queue(self, media_data: Dict, source: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—å¹¶æ™ºèƒ½å‘é€ - æ”¯æŒå›¾ç‰‡é™çº§è·å–"""

        # å¯¹äº Ani-RSSï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†å›¾ç‰‡æå–
        if source == "ani-rss":
            ani_rss_content = self.extract_ani_rss_content(media_data)
            image_url = ani_rss_content.get("image_url", "")
            message_text = ani_rss_content.get("text", "")
        else:
            image_url = media_data.get("image_url", "")
            message_text = self.generate_message_text(media_data, source)

            # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œå°è¯•è·å–é™çº§å›¾ç‰‡
            if not image_url:
                logger.info("é€šçŸ¥æ²¡æœ‰å›¾ç‰‡ï¼Œå°è¯•è·å–é™çº§å›¾ç‰‡...")
                fallback_image = await self.get_fallback_image(media_data)
                if fallback_image:
                    image_url = fallback_image
                    logger.info("æˆåŠŸè·å–é™çº§å›¾ç‰‡")
                else:
                    logger.info("é™çº§å›¾ç‰‡è·å–å¤±è´¥ï¼Œå°†ä¸å‘é€å›¾ç‰‡")

        message_payload = {
            "image_url": image_url,
            "message_text": message_text,
            "timestamp": time.time(),
            "source": source,
        }

        self.message_queue.append(message_payload)

        source_name = self.source_map.get(source, source)
        item_type = media_data.get('item_type', 'Unknown') if source != "ani-rss" else "Ani-RSS"
        logger.info(f"æ–° {item_type} é€šçŸ¥å·²åŠ å…¥é˜Ÿåˆ— [æ¥æº: {source_name}] {'(å«å›¾ç‰‡)' if image_url else '(æ— å›¾ç‰‡)'}")

        # æ™ºèƒ½å‘é€é€»è¾‘ï¼šç«‹å³æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€
        await self._check_and_send_messages()

    def _save_failed_request(self, body_text: str, headers: Dict):
        """ä¿å­˜å¤±è´¥çš„è¯·æ±‚åˆ°æ–‡ä»¶"""
        try:
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"failed_webhook_{timestamp}.txt"

            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"æ—¶é—´: {timestamp}\n")
                f.write(f"User-Agent: {headers.get('user-agent', 'N/A')}\n")
                f.write(f"Content-Type: {headers.get('content-type', 'N/A')}\n")
                f.write(f"è¯·æ±‚ä½“:\n{body_text}")

            logger.error(f"å¤±è´¥çš„è¯·æ±‚å·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥è¯·æ±‚æ—¶å‡ºé”™: {e}")

    def decode_html_entities(self, text: str) -> str:
        """è§£ç HTMLå®ä½“"""
        if not text:
            return ""
        return html.unescape(text)

    def try_fix_ani_rss_json(self, body_text: str) -> str:
        """å°è¯•ä¿®å¤ä¸å®Œæ•´çš„ ani-rss JSON"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å« ani-rss ç‰¹å¾
            if "meassage" not in body_text:
                return ""

            # å°è¯•ä¿®å¤å¸¸è§çš„ä¸å®Œæ•´ JSON é—®é¢˜
            fixed_text = body_text.strip()

            # è®¡ç®—éœ€è¦çš„é—­åˆæ‹¬å·æ•°é‡
            open_braces = fixed_text.count('{')
            close_braces = fixed_text.count('}')
            open_brackets = fixed_text.count('[')
            close_brackets = fixed_text.count(']')

            # è®°å½•ä¿®å¤å‰çš„çŠ¶æ€
            logger.info(f"JSON ä¿®å¤åˆ†æ: å¼€æ”¾æ‹¬å· {{{open_braces}, [{open_brackets}, é—­åˆæ‹¬å· }}{close_braces}, ]{close_brackets}")

            # æ·»åŠ ç¼ºå¤±çš„é—­åˆç¬¦å·ï¼ˆå…ˆæ·»åŠ ä¸­æ‹¬å·ï¼Œå†æ·»åŠ å¤§æ‹¬å·ï¼‰
            brackets_needed = open_brackets - close_brackets
            braces_needed = open_braces - close_braces

            if brackets_needed > 0:
                fixed_text += ']' * brackets_needed

            if braces_needed > 0:
                fixed_text += '}' * braces_needed

            # éªŒè¯ä¿®å¤åçš„ JSON
            try:
                parsed_data = json.loads(fixed_text)
                logger.info(f"æˆåŠŸä¿®å¤ JSONï¼Œæ·»åŠ äº† {braces_needed} ä¸ª '}}' å’Œ {brackets_needed} ä¸ª ']]'")

                # éªŒè¯æ•°æ®ç»“æ„
                if "meassage" in parsed_data:
                    messages = parsed_data["meassage"]
                    logger.info(f"ä¿®å¤åçš„ JSON åŒ…å« {len(messages)} æ¡æ¶ˆæ¯")

                return fixed_text
            except json.JSONDecodeError as e:
                logger.warning(f"ä¿®å¤åçš„ JSON ä»ç„¶æ— æ•ˆ: {e}")
                return ""

        except Exception as e:
            logger.warning(f"ä¿®å¤ JSON æ—¶å‡ºé”™: {e}")
            return ""



    def is_emby_data(self, data: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º Emby æ•°æ®æ ¼å¼"""
        # æ£€æŸ¥ Emby ç‰¹æœ‰çš„å­—æ®µç»„åˆ
        emby_fields = ["Title", "Description", "Date", "Event", "Item", "Server"]

        # æ£€æŸ¥åŸºæœ¬å­—æ®µ
        basic_match = sum(1 for field in emby_fields if field in data) >= 4

        # æ£€æŸ¥ Item å­—æ®µçš„ Emby ç‰¹å¾
        item_data = data.get("Item", {})
        if isinstance(item_data, dict):
            emby_item_fields = ["ServerId", "Id", "Type", "Name"]
            item_match = sum(1 for field in emby_item_fields if field in item_data) >= 3
            return basic_match and item_match

        return basic_match

    def is_ani_rss_data(self, data: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º ani-rss æ•°æ®æ ¼å¼"""
        # æ£€æŸ¥ ani-rss ç‰¹æœ‰çš„å­—æ®µç»„åˆ
        ani_rss_fields = [
            "notificationTemplate", "notificationType", "webHookMethod",
            "webHookUrl", "webHookBody", "statusList"
        ]

        # å¦‚æœåŒ…å«å¤šä¸ª ani-rss ç‰¹æœ‰å­—æ®µï¼Œåˆ™è®¤ä¸ºæ˜¯ ani-rss æ•°æ®
        found_fields = sum(1 for field in ani_rss_fields if field in data)
        return found_fields >= 3

    def is_ani_rss_message_format(self, data: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º ani-rss æ¶ˆæ¯æ ¼å¼"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ meassage å­—æ®µï¼ˆæ³¨æ„æ‹¼å†™ï¼‰
        if "meassage" in data:
            messages = data.get("meassage", [])
            if isinstance(messages, list) and len(messages) > 0:
                # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼
                for msg in messages:
                    if isinstance(msg, dict) and "type" in msg and "data" in msg:
                        msg_type = msg.get("type")
                        if msg_type in ["image", "text"]:
                            return True
        return False

    def is_ani_rss_text_template(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º ani-rss æ–‡æœ¬æ¨¡æ¿"""
        # æ£€æŸ¥ ani-rss æ–‡æœ¬æ¨¡æ¿çš„ç‰¹å¾
        ani_rss_template_patterns = [
            "${emoji}", "${action}", "${title}", "${score}", "${tmdburl}",
            "${themoviedbName}", "${bgmUrl}", "${season}", "${episode}",
            "${subgroup}", "${currentEpisodeNumber}", "${totalEpisodeNumber}",
            "${year}", "${month}", "${date}", "${text}", "${downloadPath}",
            "${episodeTitle}"
        ]

        # å¦‚æœåŒ…å«å¤šä¸ªæ¨¡æ¿å˜é‡ï¼Œåˆ™è®¤ä¸ºæ˜¯ ani-rss æ–‡æœ¬æ¨¡æ¿
        found_patterns = sum(1 for pattern in ani_rss_template_patterns if pattern in text)
        return found_patterns >= 3

    def parse_ani_rss_webhook_body(self, webhook_body: str) -> Dict:
        """è§£æ ani-rss çš„ webHookBody å­—æ®µ"""
        try:
            # ani-rss çš„ webHookBody å¯èƒ½åŒ…å«æ¨¡æ¿å˜é‡
            # å°è¯•æå–å…¶ä¸­çš„ç»“æ„ä¿¡æ¯
            if not webhook_body:
                return {}

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡å’Œæ–‡æœ¬ä¿¡æ¯
            has_image = "${image}" in webhook_body or "image" in webhook_body.lower()
            has_text = "${message}" in webhook_body or "text" in webhook_body.lower()

            return {
                "has_image": has_image,
                "has_text": has_text,
                "raw_body": webhook_body
            }
        except Exception as e:
            logger.warning(f"è§£æ ani-rss webHookBody å¤±è´¥: {e}")
            return {}

    def convert_ani_rss_to_media_data(self, data: Dict) -> Dict:
        """å°† ani-rss æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†åª’ä½“æ•°æ®æ ¼å¼"""
        try:
            # è§£æ webHookBody
            webhook_body = data.get("webHookBody", "")
            body_info = self.parse_ani_rss_webhook_body(webhook_body)

            # æ„å»ºæ ‡å‡†æ ¼å¼çš„åª’ä½“æ•°æ®
            media_data = {
                "item_type": "Episode",  # ani-rss ä¸»è¦å¤„ç†åŠ¨ç”»å‰§é›†
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": "æ¥è‡ª Ani-RSS çš„åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "runtime": "",
                "year": "",
                "season_number": "",
                "episode_number": "",
            }

            # å¦‚æœæ”¯æŒå›¾ç‰‡ï¼Œæ·»åŠ é»˜è®¤å›¾ç‰‡
            if body_info.get("has_image"):
                media_data["image_url"] = "https://picsum.photos/300/450"

            return media_data

        except Exception as e:
            logger.error(f"è½¬æ¢ ani-rss æ•°æ®å¤±è´¥: {e}")
            # è¿”å›åŸºæœ¬çš„åª’ä½“æ•°æ®
            return {
                "item_type": "Episode",
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": "æ¥è‡ª Ani-RSS çš„åŠ¨ç”»æ›´æ–°é€šçŸ¥"
            }

    def parse_ani_rss_text_template(self, template_text: str) -> Dict:
        """è§£æ ani-rss æ–‡æœ¬æ¨¡æ¿ï¼Œæå–å˜é‡ä¿¡æ¯"""
        import re

        # æå–æ¨¡æ¿å˜é‡çš„å€¼ï¼ˆè¿™é‡Œæ˜¯æ¨¡æ‹Ÿï¼Œå®é™…å€¼ç”± ani-rss å¡«å……ï¼‰
        template_vars = {}

        # æŸ¥æ‰¾æ‰€æœ‰æ¨¡æ¿å˜é‡
        pattern = r'\$\{([^}]+)\}'
        matches = re.findall(pattern, template_text)

        for var in matches:
            template_vars[var] = f"${{{var}}}"  # ä¿ç•™æ¨¡æ¿æ ¼å¼

        return template_vars

    def convert_ani_rss_text_template_to_media_data(self, template_text: str) -> Dict:
        """å°† ani-rss æ–‡æœ¬æ¨¡æ¿è½¬æ¢ä¸ºæ ‡å‡†åª’ä½“æ•°æ®æ ¼å¼"""
        try:
            # è§£ææ¨¡æ¿å˜é‡
            template_vars = self.parse_ani_rss_text_template(template_text)

            # æ„å»ºæ ‡å‡†æ ¼å¼çš„åª’ä½“æ•°æ®
            media_data = {
                "item_type": "Episode",
                "series_name": template_vars.get("title", "Ani-RSS é€šçŸ¥"),
                "item_name": template_vars.get("episodeTitle", "åŠ¨ç”»æ›´æ–°é€šçŸ¥"),
                "overview": f"æ¥è‡ª Ani-RSS çš„åŠ¨ç”»æ›´æ–°é€šçŸ¥\n\nåŸå§‹æ¨¡æ¿:\n{template_text[:200]}...",
                "runtime": "",
                "year": template_vars.get("year", ""),
                "season_number": template_vars.get("season", ""),
                "episode_number": template_vars.get("episode", ""),
            }

            # æ·»åŠ é¢å¤–ä¿¡æ¯åˆ° overview
            extra_info = []
            if "score" in template_vars:
                extra_info.append(f"è¯„åˆ†: {template_vars['score']}")
            if "subgroup" in template_vars:
                extra_info.append(f"å­—å¹•ç»„: {template_vars['subgroup']}")
            if "currentEpisodeNumber" in template_vars and "totalEpisodeNumber" in template_vars:
                extra_info.append(f"è¿›åº¦: {template_vars['currentEpisodeNumber']}/{template_vars['totalEpisodeNumber']}")

            if extra_info:
                media_data["overview"] += "\n\n" + "\n".join(extra_info)

            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç›¸å…³ä¿¡æ¯ï¼ˆè™½ç„¶æ¨¡æ¿ä¸­æ²¡æœ‰ç›´æ¥çš„å›¾ç‰‡URLï¼‰
            # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ é»˜è®¤å›¾ç‰‡
            if any(var in template_vars for var in ["tmdburl", "bgmUrl"]):
                media_data["image_url"] = "https://picsum.photos/300/450"

            return media_data

        except Exception as e:
            logger.error(f"è½¬æ¢ ani-rss æ–‡æœ¬æ¨¡æ¿å¤±è´¥: {e}")
            # è¿”å›åŸºæœ¬çš„åª’ä½“æ•°æ®
            return {
                "item_type": "Episode",
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": f"æ¥è‡ª Ani-RSS çš„åŠ¨ç”»æ›´æ–°é€šçŸ¥\n\n{template_text[:100]}..."
            }

    def convert_ani_rss_message_to_media_data(self, data: Dict) -> Dict:
        """å°† ani-rss æ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†åª’ä½“æ•°æ®æ ¼å¼"""
        try:
            messages = data.get("meassage", [])

            # æå–å›¾ç‰‡å’Œæ–‡æœ¬ä¿¡æ¯
            image_url = ""
            text_content = ""

            for msg in messages:
                if isinstance(msg, dict):
                    msg_type = msg.get("type")
                    msg_data = msg.get("data", {})

                    if msg_type == "image":
                        image_url = msg_data.get("file", "")
                    elif msg_type == "text":
                        text_content = msg_data.get("text", "")

            # è§£ææ–‡æœ¬å†…å®¹ä¸­çš„ä¿¡æ¯
            media_data = self.parse_ani_rss_text_content(text_content)

            # æ·»åŠ å›¾ç‰‡URL
            if image_url:
                media_data["image_url"] = image_url

            return media_data

        except Exception as e:
            logger.error(f"è½¬æ¢ ani-rss æ¶ˆæ¯æ ¼å¼å¤±è´¥: {e}")
            return {
                "item_type": "Episode",
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": "æ¥è‡ª Ani-RSS çš„åŠ¨ç”»æ›´æ–°é€šçŸ¥"
            }

    def parse_ani_rss_text_content(self, text_content: str) -> Dict:
        """è§£æ ani-rss æ–‡æœ¬å†…å®¹ï¼Œæå–åª’ä½“ä¿¡æ¯"""
        try:
            # åˆå§‹åŒ–åª’ä½“æ•°æ®
            media_data = {
                "item_type": "Episode",
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": text_content,
                "runtime": "",
                "year": "",
                "season_number": "",
                "episode_number": "",
            }

            # è§£ææ–‡æœ¬ä¸­çš„ä¿¡æ¯
            lines = text_content.split('\n')
            for line in lines:
                line = line.strip()
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()

                    if key == "æ ‡é¢˜":
                        media_data["series_name"] = value
                    elif key == "å­£":
                        media_data["season_number"] = value
                    elif key == "é›†":
                        media_data["episode_number"] = value
                    elif key == "TMDBé›†æ ‡é¢˜":
                        media_data["item_name"] = value
                    elif key == "é¦–æ’­":
                        # æå–å¹´ä»½
                        import re
                        year_match = re.search(r'(\d{4})', value)
                        if year_match:
                            media_data["year"] = year_match.group(1)

            return media_data

        except Exception as e:
            logger.error(f"è§£æ ani-rss æ–‡æœ¬å†…å®¹å¤±è´¥: {e}")
            return {
                "item_type": "Episode",
                "series_name": "Ani-RSS é€šçŸ¥",
                "item_name": "åŠ¨ç”»æ›´æ–°é€šçŸ¥",
                "overview": text_content
            }

    def convert_emby_to_media_data(self, data: Dict) -> Dict:
        """å°† Emby æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†åª’ä½“æ•°æ®æ ¼å¼"""
        try:
            item = data.get("Item", {})

            # æå–åŸºæœ¬ä¿¡æ¯
            item_type = item.get("Type", "Unknown")
            item_name = item.get("Name", "")

            # å¤„ç†å‰§é›†ä¿¡æ¯
            series_name = ""
            season_number = ""
            episode_number = ""

            if item_type == "Episode":
                # ä» Title ä¸­æå–å‰§é›†åç§°
                title = data.get("Title", "")
                if " - " in title:
                    # æ ¼å¼: "æ–° - S1, Ep3 - Tsuihousha Shokudou e Youkoso! - 03 åœ¨ AFXS-210103060"
                    parts = title.split(" - ")
                    if len(parts) >= 3:
                        series_name = parts[2].strip()

                # å¦‚æœä» Title æå–å¤±è´¥ï¼Œä½¿ç”¨ Item.Name
                if not series_name:
                    series_name = item_name

                # æå–å­£é›†ä¿¡æ¯
                season_number = str(item.get("ParentIndexNumber", ""))
                episode_number = str(item.get("IndexNumber", ""))

            # æ„å»ºåª’ä½“æ•°æ®ï¼ˆç§»é™¤å‰§æƒ…ç®€ä»‹ã€æœåŠ¡å™¨ã€é›†åç§°ï¼‰
            media_data = {
                "item_type": item_type,
                "series_name": series_name,
                "season_number": season_number,
                "episode_number": episode_number,
                "runtime": "",
                "year": "",
                "event_type": data.get("Event", ""),
                # ä¿ç•™åŸå§‹æ•°æ®ç”¨äº TMDB åŒ¹é…
                "emby_item_id": item.get("Id", ""),
                "emby_path": item.get("Path", ""),
                "emby_original_name": item_name,
            }

            # å¤„ç†è¿è¡Œæ—¶é—´
            runtime_ticks = item.get("RunTimeTicks")
            if runtime_ticks:
                # Emby ä½¿ç”¨ ticks (1 tick = 100 nanoseconds)
                # è½¬æ¢ä¸ºåˆ†é’Ÿ
                minutes = int(runtime_ticks / 10000000 / 60)
                media_data["runtime"] = f"{minutes}åˆ†é’Ÿ"

            logger.info(f"Emby æ•°æ®è½¬æ¢å®Œæˆï¼Œå‡†å¤‡ TMDB åŒ¹é…: {media_data}")
            return media_data

        except Exception as e:
            logger.error(f"è½¬æ¢ Emby æ•°æ®å¤±è´¥: {e}")
            return {
                "item_type": "Episode",
                "series_name": "Emby é€šçŸ¥",
                "season_number": "",
                "episode_number": "",
                "overview": f"æ¥è‡ª Emby çš„åª’ä½“æ›´æ–°é€šçŸ¥"
            }

    def convert_generic_media_data(self, data: Dict) -> Dict:
        """å°†é€šç”¨åª’ä½“æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼ˆé€‚ç”¨äº Jellyfinã€Plex ç­‰ï¼‰"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            item_type = data.get("ItemType") or data.get("Type") or data.get("item_type", "Episode")

            # å¤„ç†å‰§é›†åç§°
            series_name = (
                data.get("SeriesName") or
                data.get("series_name") or
                data.get("Name") or
                data.get("Title") or
                ""
            )

            # å¤„ç†é›†åç§°
            item_name = (
                data.get("Name") or
                data.get("item_name") or
                data.get("EpisodeName") or
                ""
            )

            # å¤„ç†å­£é›†ä¿¡æ¯
            season_number = str(data.get("SeasonNumber") or data.get("season_number") or "")
            episode_number = str(data.get("IndexNumber") or data.get("episode_number") or "")

            # å¤„ç†å¹´ä»½
            year = ""
            if data.get("Year"):
                year = str(data.get("Year"))
            elif data.get("ProductionYear"):
                year = str(data.get("ProductionYear"))

            # æ„å»ºåª’ä½“æ•°æ®
            media_data = {
                "item_type": item_type,
                "series_name": series_name,
                "item_name": item_name,
                "season_number": season_number,
                "episode_number": episode_number,
                "overview": data.get("Overview") or data.get("overview", ""),
                "runtime": "",
                "year": year,
                "event_type": data.get("Event") or data.get("event_type", ""),
            }

            # å¤„ç†è¿è¡Œæ—¶é—´
            runtime_ticks = data.get("RunTimeTicks")
            if runtime_ticks:
                # è½¬æ¢ä¸ºåˆ†é’Ÿ
                minutes = int(runtime_ticks / 10000000 / 60)
                media_data["runtime"] = f"{minutes}åˆ†é’Ÿ"
            elif data.get("runtime"):
                media_data["runtime"] = data.get("runtime")

            logger.info(f"é€šç”¨åª’ä½“æ•°æ®è½¬æ¢å®Œæˆï¼Œå‡†å¤‡æ•°æ®ä¸°å¯Œ: {media_data}")
            return media_data

        except Exception as e:
            logger.error(f"è½¬æ¢é€šç”¨åª’ä½“æ•°æ®å¤±è´¥: {e}")
            return {
                "item_type": "Episode",
                "series_name": "åª’ä½“é€šçŸ¥",
                "season_number": "",
                "episode_number": "",
                "overview": f"æ¥è‡ªåª’ä½“æœåŠ¡å™¨çš„æ›´æ–°é€šçŸ¥"
            }

    async def search_tmdb_tv_show(self, series_name: str) -> Optional[Dict]:
        """æœç´¢ TMDB TV èŠ‚ç›®"""
        if not self.tmdb_api_key:
            logger.warning("TMDB API Key æœªé…ç½®ï¼Œè·³è¿‡ TMDB æŸ¥è¯¢")
            return None

        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"tv_search_{series_name}"
            if cache_key in self.tmdb_cache:
                logger.info(f"ä½¿ç”¨ TMDB ç¼“å­˜: {series_name}")
                return self.tmdb_cache[cache_key]

            # æœç´¢ TV èŠ‚ç›®
            search_url = f"{self.tmdb_base_url}/search/tv"
            params = {
                "api_key": self.tmdb_api_key,
                "query": series_name,
                "language": "zh-CN"
            }

            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = data.get("results", [])
                        if results:
                            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…ç»“æœ
                            tv_show = results[0]
                            self.tmdb_cache[cache_key] = tv_show
                            logger.info(f"TMDB TV æœç´¢æˆåŠŸ: {series_name} -> {tv_show.get('name')}")
                            return tv_show
                    else:
                        logger.warning(f"TMDB TV æœç´¢å¤±è´¥: {response.status}")

            return None

        except Exception as e:
            logger.error(f"TMDB TV æœç´¢å‡ºé”™: {e}")
            return None

    async def get_tmdb_episode_details(self, tv_id: int, season_number: int, episode_number: int) -> Optional[Dict]:
        """è·å– TMDB å‰§é›†è¯¦æƒ…"""
        if not self.tmdb_api_key:
            return None

        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"episode_{tv_id}_{season_number}_{episode_number}"
            if cache_key in self.tmdb_cache:
                logger.info(f"ä½¿ç”¨ TMDB å‰§é›†ç¼“å­˜: {cache_key}")
                return self.tmdb_cache[cache_key]

            # è·å–å‰§é›†è¯¦æƒ…
            episode_url = f"{self.tmdb_base_url}/tv/{tv_id}/season/{season_number}/episode/{episode_number}"
            params = {
                "api_key": self.tmdb_api_key,
                "language": "zh-CN"
            }

            async with aiohttp.ClientSession() as session:
                async with session.get(episode_url, params=params) as response:
                    if response.status == 200:
                        episode_data = await response.json()
                        self.tmdb_cache[cache_key] = episode_data
                        logger.info(f"TMDB å‰§é›†è¯¦æƒ…è·å–æˆåŠŸ: {cache_key}")
                        return episode_data
                    else:
                        logger.warning(f"TMDB å‰§é›†è¯¦æƒ…è·å–å¤±è´¥: {response.status}")

            return None

        except Exception as e:
            logger.error(f"TMDB å‰§é›†è¯¦æƒ…è·å–å‡ºé”™: {e}")
            return None

    async def enrich_media_data_with_external_apis(self, media_data: Dict) -> Dict:
        """ä½¿ç”¨å¤–éƒ¨ API ä¸°å¯Œåª’ä½“ä¿¡æ¯ï¼ˆTMDB â†’ BGM.TV â†’ åŸå§‹æ•°æ®ï¼‰"""
        try:
            if media_data.get("item_type") != "Episode":
                return media_data

            series_name = media_data.get("series_name", "")
            season_number = media_data.get("season_number", "")
            episode_number = media_data.get("episode_number", "")

            if not all([series_name, episode_number]):
                logger.warning("ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œè·³è¿‡å¤–éƒ¨ API æŸ¥è¯¢")
                return media_data

            logger.info(f"å¼€å§‹æ•°æ®ä¸°å¯Œæµç¨‹: {series_name} ç¬¬{episode_number}é›†")

            # ç¬¬ä¸€æ­¥ï¼šå°è¯• TMDB
            if self.tmdb_api_key and season_number:
                logger.info("å°è¯•ä½¿ç”¨ TMDB è·å–æ•°æ®...")
                enriched_data = await self.try_tmdb_enrichment(media_data)
                if enriched_data.get("tmdb_enriched"):
                    logger.info("TMDB æ•°æ®è·å–æˆåŠŸ")
                    return enriched_data
                else:
                    logger.info("TMDB æ•°æ®è·å–å¤±è´¥ï¼Œå°è¯• BGM.TV")
            else:
                logger.info("TMDB API Key æœªé…ç½®æˆ–ç¼ºå°‘å­£æ•°ä¿¡æ¯ï¼Œè·³è¿‡ TMDBï¼Œå°è¯• BGM.TV")

            # ç¬¬äºŒæ­¥ï¼šå°è¯• BGM.TV
            logger.info("å°è¯•ä½¿ç”¨ BGM.TV è·å–æ•°æ®...")
            enriched_data = await self.enrich_media_data_with_bgm(media_data)
            if enriched_data.get("bgm_enriched"):
                logger.info("BGM.TV æ•°æ®è·å–æˆåŠŸ")
                return enriched_data
            else:
                logger.info("BGM.TV æ•°æ®è·å–å¤±è´¥")

            # ç¬¬ä¸‰æ­¥ï¼šå°è¯•è¡¥å…¨å›¾ç‰‡ï¼ˆå¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼‰
            if not media_data.get("image_url"):
                logger.info("å°è¯•è¡¥å…¨å›¾ç‰‡ä¿¡æ¯...")
                image_url = await self.get_fallback_image(media_data)
                if image_url:
                    media_data["image_url"] = image_url
                    logger.info("æˆåŠŸè·å–é™çº§å›¾ç‰‡")

            # ç¬¬å››æ­¥ï¼šè¿”å›åŸå§‹æ•°æ®
            logger.info("æ‰€æœ‰å¤–éƒ¨ API è·å–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            return media_data

        except Exception as e:
            logger.error(f"æ•°æ®ä¸°å¯Œæµç¨‹å¤±è´¥: {e}")
            return media_data

    async def get_fallback_image(self, media_data: Dict) -> str:
        """è·å–é™çº§å›¾ç‰‡ - TMDB â†’ BGM.TV â†’ æ— å›¾ç‰‡"""
        try:
            series_name = media_data.get("series_name", "")
            if not series_name:
                return ""

            # å°è¯•ä» TMDB è·å–å›¾ç‰‡
            if self.tmdb_api_key:
                logger.info("å°è¯•ä» TMDB è·å–å›¾ç‰‡...")
                image_url = await self.get_tmdb_image(series_name)
                if image_url:
                    logger.info("TMDB å›¾ç‰‡è·å–æˆåŠŸ")
                    return image_url

            # å°è¯•ä» BGM.TV è·å–å›¾ç‰‡
            logger.info("å°è¯•ä» BGM.TV è·å–å›¾ç‰‡...")
            image_url = await self.get_bgm_image(series_name)
            if image_url:
                logger.info("BGM.TV å›¾ç‰‡è·å–æˆåŠŸ")
                return image_url

            logger.info("æ‰€æœ‰å›¾ç‰‡æºè·å–å¤±è´¥")
            return ""

        except Exception as e:
            logger.error(f"è·å–é™çº§å›¾ç‰‡å¤±è´¥: {e}")
            return ""

    async def get_tmdb_image(self, series_name: str) -> str:
        """ä» TMDB è·å–å›¾ç‰‡"""
        try:
            tv_show = await self.search_tmdb_tv_show(series_name)
            if tv_show and tv_show.get("poster_path"):
                poster_path = tv_show["poster_path"]
                return f"https://image.tmdb.org/t/p/w500{poster_path}"
            return ""
        except Exception as e:
            logger.error(f"TMDB å›¾ç‰‡è·å–å¤±è´¥: {e}")
            return ""

    async def get_bgm_image(self, series_name: str) -> str:
        """ä» BGM.TV è·å–å›¾ç‰‡"""
        try:
            subject = await self.search_bgm_tv_show(series_name)
            if subject and subject.get("images"):
                images = subject["images"]
                # ä¼˜å…ˆä½¿ç”¨å¤§å›¾
                return images.get("large", images.get("medium", images.get("small", "")))
            return ""
        except Exception as e:
            logger.error(f"BGM.TV å›¾ç‰‡è·å–å¤±è´¥: {e}")
            return ""

    async def try_tmdb_enrichment(self, media_data: Dict) -> Dict:
        """å°è¯•ä½¿ç”¨ TMDB ä¸°å¯Œæ•°æ®"""
        try:
            series_name = media_data.get("series_name", "")
            season_number = media_data.get("season_number", "")
            episode_number = media_data.get("episode_number", "")

            # æœç´¢ TV èŠ‚ç›®
            tv_show = await self.search_tmdb_tv_show(series_name)
            if not tv_show:
                return media_data

            tv_id = tv_show.get("id")
            if not tv_id:
                return media_data

            # è·å–å‰§é›†è¯¦æƒ…
            episode_details = await self.get_tmdb_episode_details(
                tv_id, int(season_number), int(episode_number)
            )

            if episode_details:
                # æ›´æ–°åª’ä½“æ•°æ®
                enriched_data = media_data.copy()

                # æ›´æ–°å‰§é›†åç§°
                episode_name = episode_details.get("name")
                if episode_name:
                    enriched_data["item_name"] = episode_name

                # æ›´æ–°å‰§æƒ…ç®€ä»‹
                overview = episode_details.get("overview")
                if overview:
                    enriched_data["overview"] = overview

                # æ›´æ–°å¹´ä»½
                air_date = episode_details.get("air_date")
                if air_date:
                    enriched_data["year"] = air_date[:4]

                # æ·»åŠ  TMDB ä¿¡æ¯æ ‡è®°
                enriched_data["tmdb_enriched"] = True
                enriched_data["tmdb_tv_id"] = tv_id
                enriched_data["tmdb_episode_id"] = episode_details.get("id")

                return enriched_data

            return media_data

        except Exception as e:
            logger.error(f"TMDB æ•°æ®ä¸°å¯Œå¤±è´¥: {e}")
            return media_data

    async def search_bgm_tv_show(self, series_name: str) -> Optional[Dict]:
        """æœç´¢ BGM.TV èŠ‚ç›®"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"bgm_search_{series_name}"
            if cache_key in self.bgm_cache:
                logger.info(f"ä½¿ç”¨ BGM.TV ç¼“å­˜: {series_name}")
                return self.bgm_cache[cache_key]

            # æœç´¢èŠ‚ç›®
            search_url = f"{self.bgm_base_url}/search/subject/{series_name}"
            params = {
                "type": 2,  # åŠ¨ç”»ç±»å‹
                "responseGroup": "large"
            }

            async with aiohttp.ClientSession() as session:
                async with session.get(search_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        results = data.get("list", [])
                        if results:
                            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…ç»“æœ
                            subject = results[0]
                            self.bgm_cache[cache_key] = subject
                            logger.info(f"BGM.TV æœç´¢æˆåŠŸ: {series_name} -> {subject.get('name_cn') or subject.get('name')}")
                            return subject
                    else:
                        logger.warning(f"BGM.TV æœç´¢å¤±è´¥: {response.status}")

            return None

        except Exception as e:
            logger.error(f"BGM.TV æœç´¢å‡ºé”™: {e}")
            return None

    async def get_bgm_episode_details(self, subject_id: int, episode_number: int) -> Optional[Dict]:
        """è·å– BGM.TV å‰§é›†è¯¦æƒ…"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"bgm_episode_{subject_id}_{episode_number}"
            if cache_key in self.bgm_cache:
                logger.info(f"ä½¿ç”¨ BGM.TV å‰§é›†ç¼“å­˜: {cache_key}")
                return self.bgm_cache[cache_key]

            # è·å–å‰§é›†åˆ—è¡¨
            episodes_url = f"{self.bgm_base_url}/subject/{subject_id}/ep"

            async with aiohttp.ClientSession() as session:
                async with session.get(episodes_url) as response:
                    if response.status == 200:
                        episodes_data = await response.json()
                        episodes = episodes_data.get("data", [])

                        # æŸ¥æ‰¾å¯¹åº”é›†æ•°
                        for episode in episodes:
                            if episode.get("sort") == episode_number:
                                self.bgm_cache[cache_key] = episode
                                logger.info(f"BGM.TV å‰§é›†è¯¦æƒ…è·å–æˆåŠŸ: {cache_key}")
                                return episode
                    else:
                        logger.warning(f"BGM.TV å‰§é›†è¯¦æƒ…è·å–å¤±è´¥: {response.status}")

            return None

        except Exception as e:
            logger.error(f"BGM.TV å‰§é›†è¯¦æƒ…è·å–å‡ºé”™: {e}")
            return None

    async def enrich_media_data_with_bgm(self, media_data: Dict) -> Dict:
        """ä½¿ç”¨ BGM.TV æ•°æ®ä¸°å¯Œåª’ä½“ä¿¡æ¯"""
        try:
            if media_data.get("item_type") != "Episode":
                return media_data

            series_name = media_data.get("series_name", "")
            episode_number = media_data.get("episode_number", "")

            if not all([series_name, episode_number]):
                logger.warning("ç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œè·³è¿‡ BGM.TV æŸ¥è¯¢")
                return media_data

            # æœç´¢èŠ‚ç›®
            subject = await self.search_bgm_tv_show(series_name)
            if not subject:
                logger.info(f"BGM.TV æœªæ‰¾åˆ°åŒ¹é…çš„èŠ‚ç›®: {series_name}")
                return media_data

            subject_id = subject.get("id")
            if not subject_id:
                return media_data

            # è·å–å‰§é›†è¯¦æƒ…
            episode_details = await self.get_bgm_episode_details(subject_id, int(episode_number))

            if episode_details:
                # æ›´æ–°åª’ä½“æ•°æ®
                enriched_data = media_data.copy()

                # æ›´æ–°å‰§é›†åç§°
                episode_name = episode_details.get("name_cn") or episode_details.get("name")
                if episode_name:
                    enriched_data["item_name"] = episode_name

                # æ›´æ–°å‰§æƒ…ç®€ä»‹
                episode_desc = episode_details.get("desc")
                if episode_desc:
                    enriched_data["overview"] = episode_desc

                # æ›´æ–°æ’­å‡ºæ—¥æœŸ
                air_date = episode_details.get("airdate")
                if air_date:
                    enriched_data["year"] = air_date[:4]

                # æ·»åŠ  BGM.TV ä¿¡æ¯æ ‡è®°
                enriched_data["bgm_enriched"] = True
                enriched_data["bgm_subject_id"] = subject_id
                enriched_data["bgm_episode_id"] = episode_details.get("id")

                logger.info(f"BGM.TV æ•°æ®ä¸°å¯Œå®Œæˆ: {series_name} ç¬¬{episode_number}é›†")
                return enriched_data

            return media_data

        except Exception as e:
            logger.error(f"BGM.TV æ•°æ®ä¸°å¯Œå¤±è´¥: {e}")
            return media_data

    def detect_notification_source(self, data: Dict, headers: Dict) -> str:
        """æ£€æµ‹é€šçŸ¥æ¥æº"""
        # æ£€æŸ¥ User-Agent ä¸­çš„ç‰¹å¾
        user_agent = headers.get("user-agent", "").lower()

        # ä¼˜å…ˆæ£€æŸ¥ User-Agent
        if "emby server" in user_agent:
            return "emby"
        elif "jellyfin" in user_agent:
            return "jellyfin"
        elif "plex" in user_agent:
            return "plex"
        elif "ani-rss" in user_agent:
            return "ani-rss"

        # æ£€æŸ¥ Emby æ•°æ®æ ¼å¼ç‰¹å¾
        if self.is_emby_data(data):
            return "emby"

        # æ£€æŸ¥ ani-rss æ•°æ®æ ¼å¼ç‰¹å¾
        if self.is_ani_rss_message_format(data):
            return "ani-rss"

        # æ£€æŸ¥ä¼ ç»Ÿ ani-rss é…ç½®æ ¼å¼
        if self.is_ani_rss_data(data):
            return "ani-rss"

        # æ£€æŸ¥æ•°æ®å­—æ®µç‰¹å¾
        if "jellyfin" in str(data).lower():
            return "jellyfin"
        elif "emby" in str(data).lower():
            return "emby"
        elif "plex" in str(data).lower():
            return "plex"
        elif "sonarr" in str(data).lower():
            return "sonarr"
        elif "radarr" in str(data).lower():
            return "radarr"
        elif "overseerr" in str(data).lower():
            return "overseerr"
        elif "tautulli" in str(data).lower():
            return "tautulli"

        # æ£€æŸ¥ç‰¹å®šå­—æ®µ
        if data.get("server_name") or data.get("server_version"):
            return "jellyfin"  # å¸¸è§äºJellyfin
        elif data.get("application") == "Emby":
            return "emby"
        elif data.get("product") == "Plex":
            return "plex"

        return "default"

    def get_platform_prefix(self) -> str:
        """è·å–å¹³å°å‰ç¼€"""
        platform_name = self.config.get("platform_name", "aiocqhttp")
        return self.platform_prefix_map.get(platform_name.lower(), self.platform_prefix_map["default"])

    def generate_main_section(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯ä¸»è¦éƒ¨åˆ†"""
        sections = []
        item_type = data.get("item_type", "")
        series_name = data.get("series_name", "")
        item_name = data.get("item_name", "")
        year = data.get("year", "")
        season_number = data.get("season_number", "")
        episode_number = data.get("episode_number", "")

        # æ ¹æ®åª’ä½“ç±»å‹ç”Ÿæˆä¸åŒçš„ä¿¡æ¯ç»“æ„
        if item_type == "Movie":
            # ç”µå½±ä¿¡æ¯
            if item_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"ç”µå½±åç§°: {item_name}{year_text}")
            elif series_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"ç”µå½±åç§°: {series_name}{year_text}")

        elif item_type in ["Series", "Season"]:
            # å‰§é›†/å‰§å­£ä¿¡æ¯
            if series_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"å‰§é›†åç§°: {series_name}{year_text}")
            if item_type == "Season" and season_number:
                sections.append(f"å­£å·: ç¬¬{season_number}å­£")
            if item_name and item_name != series_name:
                sections.append(f"å­£åç§°: {item_name}")

        elif item_type == "Episode":
            # å‰§é›†å•é›†ä¿¡æ¯
            if series_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"å‰§é›†åç§°: {series_name}{year_text}")
            if season_number and episode_number:
                s_num = str(season_number).zfill(2)
                e_num = str(episode_number).zfill(2)
                sections.append(f"é›†å·: S{s_num}E{e_num}")
            if item_name:
                sections.append(f"é›†åç§°: {item_name}")

        elif item_type == "Album":
            # ä¸“è¾‘ä¿¡æ¯
            if item_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"ä¸“è¾‘åç§°: {item_name}{year_text}")
            if series_name and series_name != item_name:
                sections.append(f"è‰ºæœ¯å®¶: {series_name}")

        elif item_type == "Song":
            # æ­Œæ›²ä¿¡æ¯
            if item_name:
                sections.append(f"æ­Œæ›²åç§°: {item_name}")
            if series_name:
                sections.append(f"è‰ºæœ¯å®¶: {series_name}")
            if year:
                sections.append(f"å‘è¡Œå¹´ä»½: {year}")

        elif item_type == "Book":
            # å›¾ä¹¦ä¿¡æ¯
            if item_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"ä¹¦å: {item_name}{year_text}")
            if series_name and series_name != item_name:
                sections.append(f"ä½œè€…: {series_name}")

        elif item_type in ["Video", "Audio", "AudioBook"]:
            # è§†é¢‘/éŸ³é¢‘ä¿¡æ¯
            if item_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"æ ‡é¢˜: {item_name}{year_text}")
            if series_name and series_name != item_name:
                sections.append(f"åˆ›ä½œè€…: {series_name}")

        else:
            # é»˜è®¤æ ¼å¼
            if series_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"åç§°: {series_name}{year_text}")
            elif item_name:
                year_text = f" ({year})" if year else ""
                sections.append(f"åç§°: {item_name}{year_text}")

        return "\n".join(sections)

    def generate_message_text(self, data: Dict, source: str = "default") -> str:
        """ç”Ÿæˆæ¶ˆæ¯æ–‡æœ¬"""

        # å¯¹äº Ani-RSSï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®æ ¼å¼
        if source == "ani-rss":
            return self.generate_ani_rss_raw_message(data)

        item_type = data.get("item_type", "")
        cn_type = self.media_type_map.get(item_type, item_type)
        emoji = self.type_emoji_map.get(item_type, self.type_emoji_map["Default"])
        action = self.media_action_map.get(item_type, "ä¸Šçº¿")

        # æ£€æŸ¥é…ç½®é€‰é¡¹
        show_platform_prefix = self.config.get("show_platform_prefix", True)
        show_source_info = self.config.get("show_source_info", True)

        # æ„å»ºæ ‡é¢˜
        title_parts = []

        # æ·»åŠ å¹³å°å‰ç¼€
        if show_platform_prefix:
            platform_prefix = self.get_platform_prefix()
            title_parts.append(platform_prefix)

        # æ ¹æ®åª’ä½“ç±»å‹ç”Ÿæˆåˆé€‚çš„æ ‡é¢˜
        title_text = self.generate_title_by_type(item_type, cn_type, emoji, action, data)
        title_parts.append(title_text)

        # æ·»åŠ æ¥æºä¿¡æ¯
        if show_source_info and source != "default":
            source_name = self.source_map.get(source.lower(), self.source_map["default"])
            title_parts.append(f"[{source_name}]")

        title = " ".join(title_parts)
        message_parts = [title, self.generate_main_section(data)]

        # æ·»åŠ è¯¦ç»†ä¿¡æ¯
        self.add_detail_sections(message_parts, data, item_type)

        return "\n\n".join(message_parts)

    def extract_ani_rss_content(self, data: Dict) -> Dict:
        """æå– Ani-RSS çš„å†…å®¹ï¼ˆåŒ…æ‹¬å›¾ç‰‡å’Œæ–‡æœ¬ï¼‰"""
        try:
            result = {
                "text": "",
                "image_url": ""
            }

            # æ£€æŸ¥æ˜¯å¦ä¸º Ani-RSS çœŸå®æ¶ˆæ¯æ ¼å¼
            if "meassage" in data:
                messages = data.get("meassage", [])

                for msg in messages:
                    if isinstance(msg, dict):
                        msg_type = msg.get("type")
                        msg_data = msg.get("data", {})

                        if msg_type == "text":
                            result["text"] = msg_data.get("text", "")
                        elif msg_type == "image":
                            result["image_url"] = msg_data.get("file", "")

                return result

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ¨¡æ¿æ ¼å¼
            if "text_template" in data:
                result["text"] = data.get("text_template", "")
                return result

            # å…¶ä»–æ ¼å¼ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
            if isinstance(data, dict):
                # æŸ¥æ‰¾å¯èƒ½çš„æ–‡æœ¬å­—æ®µ
                for key in ["text", "message", "content", "body"]:
                    if key in data and isinstance(data[key], str):
                        result["text"] = data[key]
                        break

                # æŸ¥æ‰¾å¯èƒ½çš„å›¾ç‰‡å­—æ®µ
                for key in ["image", "image_url", "picture", "cover"]:
                    if key in data and isinstance(data[key], str):
                        result["image_url"] = data[key]
                        break

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å­—æ®µï¼Œè¿”å› JSON å­—ç¬¦ä¸²
                if not result["text"]:
                    import json
                    result["text"] = json.dumps(data, ensure_ascii=False, indent=2)

                return result

            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            if isinstance(data, str):
                result["text"] = data
                return result

            # é»˜è®¤æƒ…å†µ
            result["text"] = "æ¥è‡ª Ani-RSS çš„é€šçŸ¥"
            return result

        except Exception as e:
            logger.error(f"æå– Ani-RSS å†…å®¹å¤±è´¥: {e}")
            return {
                "text": "æ¥è‡ª Ani-RSS çš„é€šçŸ¥",
                "image_url": ""
            }

    def generate_ani_rss_raw_message(self, data: Dict) -> str:
        """ä¸º Ani-RSS ç”ŸæˆåŸå§‹æ ¼å¼æ¶ˆæ¯ï¼ˆä»…è¿”å›æ–‡æœ¬éƒ¨åˆ†ï¼‰"""
        content = self.extract_ani_rss_content(data)
        return content["text"]

    def generate_title_by_type(self, item_type: str, cn_type: str, emoji: str, action: str, data: Dict) -> str:
        """æ ¹æ®åª’ä½“ç±»å‹ç”Ÿæˆåˆé€‚çš„æ ‡é¢˜"""
        if item_type == "Movie":
            return f"{emoji} æ–°ç”µå½±{action}"
        elif item_type in ["Series", "Season"]:
            return f"{emoji} å‰§é›†{action}"
        elif item_type == "Episode":
            # å¯¹äºå‰§é›†ï¼Œæ˜¾ç¤ºæ›´å…·ä½“çš„ä¿¡æ¯
            season_num = data.get("season_number", "")
            episode_num = data.get("episode_number", "")
            if season_num and episode_num:
                return f"{emoji} æ–°å‰§é›†{action}"
            else:
                return f"{emoji} å‰§é›†{action}"
        elif item_type == "Album":
            return f"{emoji} æ–°ä¸“è¾‘{action}"
        elif item_type == "Song":
            return f"{emoji} æ–°æ­Œæ›²{action}"
        elif item_type == "Video":
            return f"{emoji} æ–°è§†é¢‘{action}"
        elif item_type in ["Audio", "AudioBook"]:
            return f"{emoji} æ–°éŸ³é¢‘{action}"
        elif item_type == "Book":
            return f"{emoji} æ–°å›¾ä¹¦{action}"
        else:
            # é»˜è®¤æ ¼å¼
            return f"{emoji} æ–°{cn_type}{action}"

    def add_detail_sections(self, message_parts: List, data: Dict, item_type: str) -> None:
        """æ·»åŠ è¯¦ç»†ä¿¡æ¯éƒ¨åˆ†"""
        # å‰§æƒ…ç®€ä»‹/å†…å®¹æè¿°
        overview = data.get("overview", "")
        if overview:
            decoded_overview = self.decode_html_entities(overview)
            if item_type == "Movie":
                message_parts.append(f"\nå‰§æƒ…ç®€ä»‹:\n{decoded_overview}")
            elif item_type in ["Series", "Season", "Episode"]:
                message_parts.append(f"\nå‰§æƒ…ç®€ä»‹:\n{decoded_overview}")
            elif item_type == "Album":
                message_parts.append(f"\nä¸“è¾‘ä»‹ç»:\n{decoded_overview}")
            elif item_type == "Song":
                message_parts.append(f"\næ­Œæ›²ä»‹ç»:\n{decoded_overview}")
            elif item_type == "Book":
                message_parts.append(f"\nå†…å®¹ç®€ä»‹:\n{decoded_overview}")
            else:
                message_parts.append(f"\nå†…å®¹ç®€ä»‹:\n{decoded_overview}")

        # æ—¶é•¿ä¿¡æ¯
        runtime = data.get("runtime", "")
        if runtime:
            if item_type == "Movie":
                message_parts.append(f"\nç‰‡é•¿: {runtime}")
            elif item_type in ["Episode", "Video"]:
                message_parts.append(f"\næ—¶é•¿: {runtime}")
            elif item_type == "Song":
                message_parts.append(f"\næ—¶é•¿: {runtime}")
            else:
                message_parts.append(f"\næ—¶é•¿: {runtime}")

        # æ•°æ®æ¥æºæ ‡è®°
        if data.get("tmdb_enriched"):
            message_parts.append("\nâœ¨ æ•°æ®æ¥æº: TMDB")
        elif data.get("bgm_enriched"):
            message_parts.append("\nâœ¨ æ•°æ®æ¥æº: BGM.TV")

    def supports_forward_messages(self, platform_name: str) -> bool:
        """æ£€æŸ¥å¹³å°æ˜¯å¦æ”¯æŒåˆå¹¶è½¬å‘åŠŸèƒ½"""
        # æ”¯æŒåˆå¹¶è½¬å‘çš„å¹³å°åˆ—è¡¨
        forward_supported_platforms = {
            "aiocqhttp",  # OneBot V11 æ ‡å‡†ï¼Œæ”¯æŒ Node ç»„ä»¶
            # å…¶ä»–æ”¯æŒåˆå¹¶è½¬å‘çš„å¹³å°å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        }

        return platform_name.lower() in forward_supported_platforms

    async def fetch_bgm_data(self) -> Optional[Dict]:
        """ä» bgm.tv è·å–éšæœºå‰§é›†æ•°æ®"""
        try:
            # BGM.TV API ç«¯ç‚¹
            # è·å–çƒ­é—¨åŠ¨ç”»åˆ—è¡¨
            api_url = "https://api.bgm.tv/search/subject/åŠ¨ç”»"

            headers = {
                'User-Agent': 'AstrBot-MediaWebhook/1.0.0 (https://github.com/Soulter/AstrBot)',
                'Accept': 'application/json'
            }

            async with aiohttp.ClientSession() as session:
                # è·å–æœç´¢ç»“æœ
                async with session.get(api_url, headers=headers, timeout=10) as resp:
                    if resp.status != 200:
                        logger.warning(f"BGM.TV API è¯·æ±‚å¤±è´¥: {resp.status}")
                        return None

                    data = await resp.json()

                    if not data.get('list'):
                        logger.warning("BGM.TV API è¿”å›ç©ºåˆ—è¡¨")
                        return None

                    # éšæœºé€‰æ‹©ä¸€ä¸ªæ¡ç›®
                    subjects = data['list']
                    if not subjects:
                        return None

                    subject = random.choice(subjects)

                    # è·å–è¯¦ç»†ä¿¡æ¯
                    subject_id = subject.get('id')
                    if subject_id:
                        detail_url = f"https://api.bgm.tv/v0/subjects/{subject_id}"
                        async with session.get(detail_url, headers=headers, timeout=10) as detail_resp:
                            if detail_resp.status == 200:
                                detail_data = await detail_resp.json()

                                # è½¬æ¢ä¸ºæ’ä»¶éœ€è¦çš„æ ¼å¼
                                return self.convert_bgm_to_test_data(detail_data)

                    # å¦‚æœè·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                    return self.convert_bgm_to_test_data(subject)

        except asyncio.TimeoutError:
            logger.warning("BGM.TV API è¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.warning(f"è·å– BGM.TV æ•°æ®å¤±è´¥: {e}")
            return None

    def convert_bgm_to_test_data(self, bgm_data: Dict) -> Dict:
        """å°† BGM.TV æ•°æ®è½¬æ¢ä¸ºæµ‹è¯•æ•°æ®æ ¼å¼"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            name = bgm_data.get('name', 'æœªçŸ¥ä½œå“')
            name_cn = bgm_data.get('name_cn', name)

            # ä½¿ç”¨ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå
            series_name = name_cn if name_cn else name

            # æå–å¹´ä»½
            year = ""
            air_date = bgm_data.get('air_date', '')
            if air_date:
                try:
                    year = air_date.split('-')[0]
                except:
                    pass

            # æå–ç®€ä»‹
            summary = bgm_data.get('summary', '')
            if len(summary) > 200:
                summary = summary[:200] + "..."

            # æå–å›¾ç‰‡
            image_url = ""
            images = bgm_data.get('images', {})
            if images:
                # ä¼˜å…ˆä½¿ç”¨å¤§å›¾
                image_url = images.get('large', images.get('medium', images.get('small', '')))

            # éšæœºç”Ÿæˆé›†æ•°ä¿¡æ¯
            season_number = random.randint(1, 3)
            episode_number = random.randint(1, 24)

            return {
                "item_type": "Episode",
                "series_name": series_name,
                "year": year,
                "item_name": f"ç¬¬{episode_number}è¯",
                "season_number": season_number,
                "episode_number": episode_number,
                "overview": summary or "æš‚æ— å‰§æƒ…ç®€ä»‹",
                "runtime": f"{random.randint(20, 30)}åˆ†é’Ÿ",
                "image_url": image_url
            }

        except Exception as e:
            logger.warning(f"è½¬æ¢ BGM.TV æ•°æ®å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ•°æ®
            return {
                "item_type": "Episode",
                "series_name": "æ•°æ®è½¬æ¢å¤±è´¥",
                "year": "2024",
                "item_name": "æµ‹è¯•é›†åç§°",
                "season_number": 1,
                "episode_number": 1,
                "overview": "æ— æ³•è·å–å‰§æƒ…ç®€ä»‹",
                "runtime": "24åˆ†é’Ÿ",
            }

    async def start_batch_processor(self):
        """å¯åŠ¨æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        while True:
            try:
                interval = self.config.get("batch_interval_seconds", 300)
                await asyncio.sleep(interval)
                await self.process_message_queue()
            except Exception as e:
                logger.error(f"æ‰¹é‡å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")

    async def process_message_queue(self):
        """å¤„ç†æ¶ˆæ¯é˜Ÿåˆ— - ä¼˜åŒ–é…ç½®è·å–"""
        if not self.message_queue:
            return

        if not self.group_id:
            logger.warning("æœªé…ç½®ç¾¤ç»„IDï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return

        # æ¸…ç† group_idï¼Œç§»é™¤å¯èƒ½çš„å†’å·
        group_id = str(self.group_id).replace(":", "_")
        logger.debug(f"ä½¿ç”¨ç¾¤ç»„ID: {group_id}")

        messages = self.message_queue.copy()
        self.message_queue.clear()

        logger.info(f"ä»é˜Ÿåˆ—ä¸­å–å‡º {len(messages)} æ¡å¾…å‘æ¶ˆæ¯")

        try:
            # ä½¿ç”¨ç¼“å­˜çš„é…ç½®å€¼
            batch_min_size = self.batch_min_size
            platform_name = self.platform_name
            force_individual = self.force_individual_send

            # æ ¹æ® aiocqhttp æ–‡æ¡£ä¼˜åŒ–çš„å‘é€é€»è¾‘
            if len(messages) < batch_min_size:
                # ä½äº batch_min_size é˜ˆå€¼ï¼Œä½¿ç”¨å•ç‹¬å‘é€ï¼ˆç¬¦åˆ aiocqhttp æ–‡æ¡£å»ºè®®ï¼‰
                logger.info(f"æ¶ˆæ¯æ•°é‡ {len(messages)} ä½äºæ‰¹é‡å‘é€é˜ˆå€¼ {batch_min_size}ï¼Œä½¿ç”¨å•ç‹¬å‘é€")
                await self.send_individual_messages(group_id, messages)
            elif force_individual:
                # å¼ºåˆ¶å•ç‹¬å‘é€
                logger.info(f"é…ç½®å¼ºåˆ¶å•ç‹¬å‘é€ï¼Œå°† {len(messages)} æ¡æ¶ˆæ¯é€ä¸ªå‘é€")
                await self.send_individual_messages(group_id, messages)
            elif self.supports_forward_messages(platform_name):
                # è¾¾åˆ°æˆ–è¶…è¿‡ batch_min_size é˜ˆå€¼ï¼Œä½¿ç”¨åˆå¹¶è½¬å‘
                logger.info(f"æ¶ˆæ¯æ•°é‡ {len(messages)} è¾¾åˆ°é˜ˆå€¼ {batch_min_size}ï¼Œå¹³å° {platform_name} æ”¯æŒåˆå¹¶è½¬å‘ï¼Œä½¿ç”¨åˆå¹¶å‘é€")
                await self.send_batch_messages(group_id, messages)
            else:
                # å¹³å°ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼Œå›é€€åˆ°å•ç‹¬å‘é€
                logger.info(f"å¹³å° {platform_name} ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼Œå°† {len(messages)} æ¡æ¶ˆæ¯é€ä¸ªå‘é€")
                await self.send_individual_messages(group_id, messages)

        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    async def send_batch_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€æ‰¹é‡åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼ˆä»…æ”¯æŒ aiocqhttp ç­‰å¹³å°ï¼‰- ä¼˜åŒ–é…ç½®è·å–"""
        logger.info(f"ä½¿ç”¨åˆå¹¶è½¬å‘å‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        # æ ¹æ® aiocqhttp æ–‡æ¡£ï¼Œä½äº batch_min_size ä½¿ç”¨å•ç‹¬å‘é€
        if len(messages) < self.batch_min_size:
            logger.info(f"æ¶ˆæ¯æ•°é‡ {len(messages)} ä½äºæ‰¹é‡é˜ˆå€¼ {self.batch_min_size}ï¼Œæ”¹ä¸ºå•ç‹¬å‘é€")
            await self.send_individual_messages(group_id, messages)
            return

        # æ„å»ºåˆå¹¶è½¬å‘èŠ‚ç‚¹
        forward_nodes = []

        for msg in messages:
            try:
                content = []

                # æ·»åŠ å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if msg.get("image_url"):
                    content.append(Comp.Image.fromURL(msg["image_url"]))

                # å¤„ç†æ¶ˆæ¯æ–‡æœ¬
                message_text = msg["message_text"]

                # å¯¹äºåˆå¹¶è½¬å‘ï¼Œä¹Ÿä½¿ç”¨ç›¸åŒçš„æ–‡æœ¬å¤„ç†
                if self.platform_name.lower() == "aiocqhttp":
                    processed_text = self._process_text_for_aiocqhttp(message_text)
                    content.append(Comp.Plain(processed_text))
                else:
                    content.append(Comp.Plain(message_text))

                # æ ¹æ® AstrBot æ–‡æ¡£ï¼Œä½¿ç”¨æ­£ç¡®çš„ Node æ ¼å¼
                node = Comp.Node(
                    uin="2659908767",  # å¯ä»¥é…ç½®åŒ–
                    name="åª’ä½“é€šçŸ¥",
                    content=content
                )
                forward_nodes.append(node)

            except Exception as e:
                logger.error(f"æ„å»ºè½¬å‘èŠ‚ç‚¹å¤±è´¥: {e}")
                logger.error(f"æ¶ˆæ¯å†…å®¹: {msg}")

        if forward_nodes:
            try:
                # å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯
                unified_msg_origin = f"{self.platform_name}:GroupMessage:{group_id}"
                logger.debug(f"å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼Œunified_msg_origin: {unified_msg_origin}")

                # æ ¹æ® AstrBot æ–‡æ¡£ï¼Œç›´æ¥å‘é€ Node åˆ—è¡¨
                message_chain = MessageChain(chain=forward_nodes)
                await self.context.send_message(unified_msg_origin, message_chain)

                logger.info(f"æˆåŠŸå‘é€ {len(forward_nodes)} æ¡åˆå¹¶è½¬å‘æ¶ˆæ¯")
            except Exception as e:
                logger.error(f"å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯å¤±è´¥: {e}")
                logger.info("å›é€€åˆ°å•ç‹¬å‘é€æ¨¡å¼")
                await self.send_individual_messages(group_id, messages)
        else:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è½¬å‘èŠ‚ç‚¹ï¼Œæ”¹ä¸ºå•ç‹¬å‘é€")
            await self.send_individual_messages(group_id, messages)

    async def send_individual_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€å•ç‹¬æ¶ˆæ¯ï¼ˆé€‚ç”¨äºæ‰€æœ‰å¹³å°ï¼‰"""
        logger.info(f"é€ä¸ªå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        unified_msg_origin = f"{self.platform_name}:GroupMessage:{group_id}"
        logger.debug(f"å‘é€å•ç‹¬æ¶ˆæ¯ï¼Œunified_msg_origin: {unified_msg_origin}")

        # é¢„è®¡ç®—æ˜¯å¦ä¸º aiocqhttp å¹³å°ï¼Œé¿å…é‡å¤åˆ¤æ–­
        is_aiocqhttp = self.platform_name.lower() == "aiocqhttp"

        for msg in messages:
            try:
                content = []

                # æ·»åŠ å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if msg.get("image_url"):
                    content.append(Comp.Image.fromURL(msg["image_url"]))

                # å¤„ç†æ¶ˆæ¯æ–‡æœ¬ï¼Œç¡®ä¿æ¢è¡Œç¬¦æ­£ç¡®å¤„ç†
                message_text = msg["message_text"]

                # å¯¹äº aiocqhttpï¼Œä½¿ç”¨ç‰¹æ®Šçš„æ¢è¡Œç¬¦å¤„ç†
                if is_aiocqhttp:
                    # å°è¯•ä¸åŒçš„æ¢è¡Œç¬¦å¤„ç†æ–¹å¼
                    processed_text = self._process_text_for_aiocqhttp(message_text)
                    content.append(Comp.Plain(processed_text))
                else:
                    # å…¶ä»–å¹³å°ç›´æ¥ä½¿ç”¨å®Œæ•´æ¶ˆæ¯
                    content.append(Comp.Plain(message_text))

                message_chain = MessageChain(chain=content)
                await self.context.send_message(unified_msg_origin, message_chain)

                # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…æ¶ˆæ¯å‘é€è¿‡å¿«
                await asyncio.sleep(0.1)

            except Exception as e:
                logger.error(f"å‘é€å•æ¡æ¶ˆæ¯å¤±è´¥: {e}")
                logger.error(f"æ¶ˆæ¯å†…å®¹: {msg}")

        logger.info(f"æˆåŠŸé€ä¸ªå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

    def _process_text_for_aiocqhttp(self, message_text: str) -> str:
        """ä¸º aiocqhttp å¤„ç†æ¶ˆæ¯æ–‡æœ¬"""
        # åŸºäºæµ‹è¯•ç»“æœï¼Œä½¿ç”¨æœ€ä½³çš„ä¿®å¤æ–¹æ¡ˆ

        # é¦–å…ˆæ ‡å‡†åŒ–æ¢è¡Œç¬¦
        processed_text = message_text.replace('\r\n', '\n').replace('\r', '\n')

        # å¯¹äº Emby/Plex/Jellyfin çš„æ¶ˆæ¯ï¼Œåº”ç”¨æ ¼å¼æ¸…ç†
        if any(platform in message_text for platform in ['[Emby]', '[Plex]', '[Jellyfin]']):
            # æ–¹æ¡ˆ3+5ç»„åˆï¼šç§»é™¤åŒæ¢è¡Œç¬¦å¹¶ç§»é™¤ç©ºè¡Œ
            lines = processed_text.split('\n')
            # ç§»é™¤ç©ºè¡Œï¼Œä¿æŒç´§å‡‘æ ¼å¼
            non_empty_lines = [line for line in lines if line.strip()]
            processed_text = '\n'.join(non_empty_lines)

            logger.debug(f"aiocqhttp æ¶ˆæ¯å¤„ç†: {len(lines)} è¡Œ -> {len(non_empty_lines)} è¡Œ")

        return processed_text

    def _split_message_for_aiocqhttp(self, message_text: str) -> List[str]:
        """ä¸º aiocqhttp æ‹†åˆ†æ¶ˆæ¯æ–‡æœ¬ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # å°†æ¶ˆæ¯æŒ‰åŒæ¢è¡Œç¬¦æ‹†åˆ†ä¸ºæ®µè½
        paragraphs = message_text.split('\n\n')

        result = []
        for paragraph in paragraphs:
            if paragraph.strip():
                # ä¿æŒæ®µè½å†…çš„å•æ¢è¡Œç¬¦
                result.append(paragraph.strip())

        return result

    @filter.command("webhook status")
    async def webhook_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹WebhookçŠ¶æ€"""
        port = self.config.get("webhook_port", 60071)
        path = self.config.get("webhook_path", "/media-webhook")
        queue_size = len(self.message_queue)
        cache_size = len(self.request_cache)

        platform_name = self.config.get("platform_name", "aiocqhttp")
        supports_forward = self.supports_forward_messages(platform_name)
        force_individual = self.config.get("force_individual_send", False)

        # ç¡®å®šå‘é€ç­–ç•¥
        if force_individual:
            send_strategy = "å¼ºåˆ¶å•ç‹¬å‘é€"
        elif supports_forward:
            send_strategy = f"æ™ºèƒ½å‘é€ï¼ˆæ”¯æŒåˆå¹¶è½¬å‘ï¼‰"
        else:
            send_strategy = f"å•ç‹¬å‘é€ï¼ˆå¹³å°ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼‰"

        status_text = f"""ğŸ“Š Media Webhook çŠ¶æ€
ğŸŒ æœåŠ¡åœ°å€: http://localhost:{port}{path}
ğŸ¯ ç›®æ ‡ç¾¤ç»„: {self.config.get('group_id', 'æœªé…ç½®')}
ğŸ”— æ¶ˆæ¯å¹³å°: {platform_name}
ğŸ“¤ å‘é€ç­–ç•¥: {send_strategy}
ğŸ”€ åˆå¹¶è½¬å‘æ”¯æŒ: {'âœ…' if supports_forward else 'âŒ'}

ğŸ“‹ é˜Ÿåˆ—æ¶ˆæ¯æ•°: {queue_size}
ğŸ—‚ï¸ ç¼“å­˜è¯·æ±‚æ•°: {cache_size}
âš™ï¸ æ‰¹é‡å‘é€é˜ˆå€¼: {self.config.get('batch_min_size', 3)}
â° å¤„ç†é—´éš”: {self.config.get('batch_interval_seconds', 300)}ç§’"""

        yield event.plain_result(status_text)

    @filter.command("webhook test")
    async def webhook_test(self, event: AstrMessageEvent, source: str = "bgm"):
        """æµ‹è¯•WebhookåŠŸèƒ½

        Args:
            source: æ•°æ®æº (bgm/static)ï¼Œé»˜è®¤ä¸º bgm
        """
        if source.lower() in ["bgm", "bangumi"]:
            yield event.plain_result("ğŸ”„ è·å– BGM.TV æ•°æ®...")
            test_data = await self.fetch_bgm_data()
            if not test_data:
                test_data = self.get_default_test_data()
                yield event.plain_result("âŒ BGM.TV è·å–å¤±è´¥ï¼Œä½¿ç”¨é™æ€æ•°æ®")
            else:
                yield event.plain_result("âœ… BGM.TV æ•°æ®è·å–æˆåŠŸ")
        else:
            test_data = self.get_default_test_data()

        # ç”Ÿæˆæ¶ˆæ¯
        test_source = "jellyfin" if source.lower() in ["bgm", "bangumi"] else "default"
        message_text = self.generate_message_text(test_data, test_source)

        content = []
        image_url = test_data.get("image_url")
        if image_url:
            try:
                content.append(Comp.Image.fromURL(str(image_url)))
            except Exception as e:
                logger.warning(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
                content.append(Comp.Plain(f"[å›¾ç‰‡åŠ è½½å¤±è´¥]\n\n"))
        content.append(Comp.Plain(message_text))

        yield event.chain_result(content)

    def get_default_test_data(self) -> Dict:
        """è·å–é»˜è®¤æµ‹è¯•æ•°æ®"""
        return {
            "item_type": "Episode",
            "series_name": "æµ‹è¯•å‰§é›†",
            "year": "2024",
            "item_name": "æµ‹è¯•é›†åç§°",
            "season_number": 1,
            "episode_number": 1,
            "overview": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‰§æƒ…ç®€ä»‹",
            "runtime": "45åˆ†é’Ÿ",
        }

    @filter.command("webhook test simple")
    async def webhook_test_simple(self, event: AstrMessageEvent):
        """ç®€å•æµ‹è¯•WebhookåŠŸèƒ½ï¼ˆä¸åŒ…å«å›¾ç‰‡ï¼‰"""
        test_data = {
            "item_type": "Episode",
            "series_name": "æµ‹è¯•å‰§é›†",
            "year": "2024",
            "item_name": "æµ‹è¯•é›†åç§°",
            "season_number": 1,
            "episode_number": 1,
            "overview": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‰§æƒ…ç®€ä»‹",
            "runtime": "45åˆ†é’Ÿ",
        }

        message_text = self.generate_message_text(test_data, "default")
        yield event.plain_result(message_text)

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        try:
            if self.site:
                await self.site.stop()
            if self.runner:
                await self.runner.cleanup()
            logger.info("Media Webhook æœåŠ¡å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ Webhook æœåŠ¡æ—¶å‡ºé”™: {e}")
