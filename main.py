import asyncio
import hashlib
import html
import json
import random
import time
from typing import Dict, List, Optional

import astrbot.api.message_components as Comp
import aiohttp
from aiohttp import web
from aiohttp.web import Request, Response
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.star import Context, Star, register


@register(
    "media_webhook",
    "Assistant",
    "åª’ä½“é€šçŸ¥ Webhook æ’ä»¶",
    "1.0.0",
    "https://github.com/example/astrbot_plugin_media_webhook",
)
class MediaWebhookPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.app = None
        self.runner = None
        self.site = None

        # æ¶ˆæ¯é˜Ÿåˆ—å’Œç¼“å­˜
        self.message_queue: List[Dict] = []
        self.request_cache: Dict[str, float] = {}  # hash -> timestamp

        # åª’ä½“ç±»å‹æ˜ å°„
        self.media_type_map = {
            "Movie": "ç”µå½±",
            "Series": "å‰§é›†",
            "Season": "å‰§å­£",
            "Episode": "å•é›†",
            "Album": "ä¸“è¾‘",
            "Song": "æ­Œæ›²",
            "Video": "è§†é¢‘",
        }
        self.type_emoji_map = {"Season": "ğŸ¬", "Episode": "ğŸ“º", "Default": "ğŸŒŸ"}

        # éªŒè¯é…ç½®
        self.validate_config()

        # å¯åŠ¨HTTPæœåŠ¡å™¨å’Œå®šæ—¶ä»»åŠ¡
        asyncio.create_task(self.start_webhook_server())
        asyncio.create_task(self.start_batch_processor())

    def validate_config(self):
        """éªŒè¯é…ç½®å‚æ•°"""
        port = self.config.get("webhook_port", 60071)
        if not isinstance(port, int) or port < 1 or port > 65535:
            logger.warning(f"æ— æ•ˆçš„ç«¯å£å·: {port}ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 60071")
            self.config["webhook_port"] = 60071

        batch_interval = self.config.get("batch_interval_seconds", 300)
        if not isinstance(batch_interval, int) or batch_interval < 10:
            logger.warning(f"æ‰¹é‡å¤„ç†é—´éš”è¿‡çŸ­: {batch_interval}ç§’ï¼Œè®¾ç½®ä¸ºæœ€å°å€¼ 10ç§’")
            self.config["batch_interval_seconds"] = max(10, batch_interval)

        cache_ttl = self.config.get("cache_ttl_seconds", 300)
        if not isinstance(cache_ttl, int) or cache_ttl < 60:
            logger.warning(f"ç¼“å­˜TTLè¿‡çŸ­: {cache_ttl}ç§’ï¼Œè®¾ç½®ä¸ºæœ€å°å€¼ 60ç§’")
            self.config["cache_ttl_seconds"] = max(60, cache_ttl)

    async def start_webhook_server(self):
        """å¯åŠ¨HTTP WebhookæœåŠ¡å™¨"""
        try:
            self.app = web.Application()
            self.app.router.add_post(
                self.config.get("webhook_path", "/media-webhook"), self.handle_webhook
            )

            self.runner = web.AppRunner(self.app)
            await self.runner.setup()

            port = self.config.get("webhook_port", 60071)
            self.site = web.TCPSite(self.runner, "0.0.0.0", port)
            await self.site.start()

            logger.info(f"Media Webhook æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: {port}")
            logger.info(
                f"è®¿é—®åœ°å€: http://localhost:{port}{self.config.get('webhook_path', '/media-webhook')}"
            )

        except OSError as e:
            if "Address already in use" in str(e) or "Only one usage" in str(e):
                logger.error(
                    f"ç«¯å£ {self.config.get('webhook_port', 60071)} å·²è¢«å ç”¨ï¼Œè¯·æ›´æ¢ç«¯å£"
                )
            else:
                logger.error(f"ç½‘ç»œé”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"å¯åŠ¨ Webhook æœåŠ¡å™¨å¤±è´¥: {e}")

    async def handle_webhook(self, request: Request) -> Response:
        """å¤„ç†Webhookè¯·æ±‚"""
        try:
            # è§£æè¯·æ±‚ä½“
            body_text = await request.text()
            if not body_text:
                return Response(text="è¯·æ±‚ä½“ä¸ºç©º", status=400)

            media_data = json.loads(body_text)

            # è®¡ç®—è¯·æ±‚å“ˆå¸Œå€¼
            request_hash = self.calculate_body_hash(media_data)

            # æ£€æŸ¥é‡å¤è¯·æ±‚
            if request_hash and self.is_duplicate_request(request_hash):
                logger.warning(f"æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå·²å¿½ç•¥ã€‚[hash: {request_hash}]")
                return Response(text="é‡å¤è¯·æ±‚å·²è¢«å¿½ç•¥", status=202)

            # ç¼“å­˜è¯·æ±‚å“ˆå¸Œ
            if request_hash:
                cache_ttl = self.config.get("cache_ttl_seconds", 300)
                self.request_cache[request_hash] = time.time() + cache_ttl

            # ç”Ÿæˆæ¶ˆæ¯å†…å®¹
            message_payload = {
                "image_url": media_data.get("image_url", ""),
                "message_text": self.generate_message_text(media_data),
                "timestamp": time.time(),
            }

            # æ·»åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            self.message_queue.append(message_payload)

            logger.info(
                f"æ–° {media_data.get('item_type', 'Unknown')} é€šçŸ¥å·²åŠ å…¥é˜Ÿåˆ—ã€‚[hash: {request_hash}]"
            )
            return Response(text="æ¶ˆæ¯å·²åŠ å…¥é˜Ÿåˆ—", status=200)

        except json.JSONDecodeError:
            logger.error("Webhook è¯·æ±‚ä½“è§£æå¤±è´¥: æ— æ•ˆçš„JSONæ ¼å¼")
            return Response(text="æ— æ•ˆçš„JSONæ ¼å¼", status=400)
        except Exception as e:
            logger.error(f"Webhook å¤„ç†å‡ºé”™: {e}")
            return Response(text="å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯", status=500)

    def calculate_body_hash(self, body: Dict) -> Optional[str]:
        """è®¡ç®—è¯·æ±‚ä½“å“ˆå¸Œå€¼"""
        try:
            body_for_hash = body.copy()
            body_for_hash.pop("image_url", None)  # æ’é™¤å›¾ç‰‡URL
            body_string = json.dumps(body_for_hash, sort_keys=True)
            return hashlib.md5(body_string.encode()).hexdigest()
        except Exception as e:
            logger.error(f"MD5 å“ˆå¸Œè®¡ç®—å¤±è´¥: {e}")
            return None

    def is_duplicate_request(self, request_hash: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚"""
        current_time = time.time()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        expired_keys = [k for k, v in self.request_cache.items() if v < current_time]
        for key in expired_keys:
            del self.request_cache[key]

        return request_hash in self.request_cache

    def decode_html_entities(self, text: str) -> str:
        """è§£ç HTMLå®ä½“"""
        if not text:
            return ""
        return html.unescape(text)

    def generate_main_section(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯ä¸»è¦éƒ¨åˆ†"""
        sections = []
        series_name = data.get("series_name", "")
        year = data.get("year", "")
        item_type = data.get("item_type", "")
        item_name = data.get("item_name", "")
        season_number = data.get("season_number", "")
        episode_number = data.get("episode_number", "")

        if series_name:
            year_text = f" ({year})" if year else ""
            sections.append(f"å‰§é›†åç§°: {series_name}{year_text}")

        if item_type == "Season":
            if item_name:
                sections.append(f"å­£åç§°: {item_name}")
            if season_number:
                sections.append(f"å­£å·: {season_number}")
        elif item_type == "Episode":
            if season_number and episode_number:
                s_num = str(season_number).zfill(2)
                e_num = str(episode_number).zfill(2)
                sections.append(f"é›†å·: S{s_num}E{e_num}")
            if item_name:
                sections.append(f"é›†åç§°: {item_name}")
        else:
            if item_name:
                sections.append(f"åç§°: {item_name}")
            if year:
                sections.append(f"å¹´ä»½: {year}")

        return "\n".join(sections)

    def generate_message_text(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯æ–‡æœ¬"""
        item_type = data.get("item_type", "")
        cn_type = self.media_type_map.get(item_type, item_type)
        emoji = self.type_emoji_map.get(item_type, self.type_emoji_map["Default"])

        message_parts = [f"{emoji} æ–°{cn_type}ä¸Šçº¿", self.generate_main_section(data)]

        overview = data.get("overview", "")
        if overview:
            decoded_overview = self.decode_html_entities(overview)
            message_parts.append(f"\nå‰§æƒ…ç®€ä»‹:\n{decoded_overview}")

        runtime = data.get("runtime", "")
        if runtime:
            message_parts.append(f"\næ—¶é•¿: {runtime}")

        return "\n\n".join(message_parts)

    def supports_forward_messages(self, platform_name: str) -> bool:
        """æ£€æŸ¥å¹³å°æ˜¯å¦æ”¯æŒåˆå¹¶è½¬å‘åŠŸèƒ½"""
        # æ”¯æŒåˆå¹¶è½¬å‘çš„å¹³å°åˆ—è¡¨
        forward_supported_platforms = {
            "aiocqhttp",  # OneBot V11 æ ‡å‡†ï¼Œæ”¯æŒ Node ç»„ä»¶
            # å…¶ä»–æ”¯æŒåˆå¹¶è½¬å‘çš„å¹³å°å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        }

        return platform_name.lower() in forward_supported_platforms

    async def fetch_bgm_data(self) -> Optional[Dict]:
        """ä» bgm.tv è·å–éšæœºå‰§é›†æ•°æ®"""
        try:
            # BGM.TV API ç«¯ç‚¹
            # è·å–çƒ­é—¨åŠ¨ç”»åˆ—è¡¨
            api_url = "https://api.bgm.tv/search/subject/åŠ¨ç”»"

            headers = {
                'User-Agent': 'AstrBot-MediaWebhook/1.0.0 (https://github.com/Soulter/AstrBot)',
                'Accept': 'application/json'
            }

            async with aiohttp.ClientSession() as session:
                # è·å–æœç´¢ç»“æœ
                async with session.get(api_url, headers=headers, timeout=10) as resp:
                    if resp.status != 200:
                        logger.warning(f"BGM.TV API è¯·æ±‚å¤±è´¥: {resp.status}")
                        return None

                    data = await resp.json()

                    if not data.get('list'):
                        logger.warning("BGM.TV API è¿”å›ç©ºåˆ—è¡¨")
                        return None

                    # éšæœºé€‰æ‹©ä¸€ä¸ªæ¡ç›®
                    subjects = data['list']
                    if not subjects:
                        return None

                    subject = random.choice(subjects)

                    # è·å–è¯¦ç»†ä¿¡æ¯
                    subject_id = subject.get('id')
                    if subject_id:
                        detail_url = f"https://api.bgm.tv/v0/subjects/{subject_id}"
                        async with session.get(detail_url, headers=headers, timeout=10) as detail_resp:
                            if detail_resp.status == 200:
                                detail_data = await detail_resp.json()

                                # è½¬æ¢ä¸ºæ’ä»¶éœ€è¦çš„æ ¼å¼
                                return self.convert_bgm_to_test_data(detail_data)

                    # å¦‚æœè·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                    return self.convert_bgm_to_test_data(subject)

        except asyncio.TimeoutError:
            logger.warning("BGM.TV API è¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.warning(f"è·å– BGM.TV æ•°æ®å¤±è´¥: {e}")
            return None

    def convert_bgm_to_test_data(self, bgm_data: Dict) -> Dict:
        """å°† BGM.TV æ•°æ®è½¬æ¢ä¸ºæµ‹è¯•æ•°æ®æ ¼å¼"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            name = bgm_data.get('name', 'æœªçŸ¥ä½œå“')
            name_cn = bgm_data.get('name_cn', name)

            # ä½¿ç”¨ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå
            series_name = name_cn if name_cn else name

            # æå–å¹´ä»½
            year = ""
            air_date = bgm_data.get('air_date', '')
            if air_date:
                try:
                    year = air_date.split('-')[0]
                except:
                    pass

            # æå–ç®€ä»‹
            summary = bgm_data.get('summary', '')
            if len(summary) > 200:
                summary = summary[:200] + "..."

            # æå–å›¾ç‰‡
            image_url = ""
            images = bgm_data.get('images', {})
            if images:
                # ä¼˜å…ˆä½¿ç”¨å¤§å›¾
                image_url = images.get('large', images.get('medium', images.get('small', '')))

            # éšæœºç”Ÿæˆé›†æ•°ä¿¡æ¯
            season_number = random.randint(1, 3)
            episode_number = random.randint(1, 24)

            return {
                "item_type": "Episode",
                "series_name": series_name,
                "year": year,
                "item_name": f"ç¬¬{episode_number}è¯",
                "season_number": season_number,
                "episode_number": episode_number,
                "overview": summary or "æš‚æ— å‰§æƒ…ç®€ä»‹",
                "runtime": f"{random.randint(20, 30)}åˆ†é’Ÿ",
                "image_url": image_url
            }

        except Exception as e:
            logger.warning(f"è½¬æ¢ BGM.TV æ•°æ®å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ•°æ®
            return {
                "item_type": "Episode",
                "series_name": "æ•°æ®è½¬æ¢å¤±è´¥",
                "year": "2024",
                "item_name": "æµ‹è¯•é›†åç§°",
                "season_number": 1,
                "episode_number": 1,
                "overview": "æ— æ³•è·å–å‰§æƒ…ç®€ä»‹",
                "runtime": "24åˆ†é’Ÿ",
            }

    async def start_batch_processor(self):
        """å¯åŠ¨æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        while True:
            try:
                interval = self.config.get("batch_interval_seconds", 300)
                await asyncio.sleep(interval)
                await self.process_message_queue()
            except Exception as e:
                logger.error(f"æ‰¹é‡å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")

    async def process_message_queue(self):
        """å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—"""
        if not self.message_queue:
            return

        group_id = self.config.get("group_id", "")
        if not group_id:
            logger.warning("æœªé…ç½®ç¾¤ç»„IDï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return

        # æ¸…ç† group_idï¼Œç§»é™¤å¯èƒ½çš„å†’å·
        group_id = str(group_id).replace(":", "_")
        logger.debug(f"ä½¿ç”¨ç¾¤ç»„ID: {group_id}")

        messages = self.message_queue.copy()
        self.message_queue.clear()

        logger.info(f"ä»é˜Ÿåˆ—ä¸­å–å‡º {len(messages)} æ¡å¾…å‘æ¶ˆæ¯")

        try:
            batch_min_size = self.config.get("batch_min_size", 3)
            platform_name = self.config.get("platform_name", "aiocqhttp")
            force_individual = self.config.get("force_individual_send", False)

            # æ™ºèƒ½å‘é€é€»è¾‘
            if len(messages) < batch_min_size:
                # æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼Œç›´æ¥å•ç‹¬å‘é€
                logger.info(f"æ¶ˆæ¯æ•°é‡ {len(messages)} ä½äºæ‰¹é‡å‘é€é˜ˆå€¼ {batch_min_size}ï¼Œä½¿ç”¨å•ç‹¬å‘é€")
                await self.send_individual_messages(group_id, messages)
            elif force_individual:
                # å¼ºåˆ¶å•ç‹¬å‘é€
                logger.info(f"é…ç½®å¼ºåˆ¶å•ç‹¬å‘é€ï¼Œå°† {len(messages)} æ¡æ¶ˆæ¯é€ä¸ªå‘é€")
                await self.send_individual_messages(group_id, messages)
            elif self.supports_forward_messages(platform_name):
                # å¹³å°æ”¯æŒåˆå¹¶è½¬å‘ï¼Œä½¿ç”¨åˆå¹¶å‘é€
                logger.info(f"å¹³å° {platform_name} æ”¯æŒåˆå¹¶è½¬å‘ï¼Œå°† {len(messages)} æ¡æ¶ˆæ¯åˆå¹¶å‘é€")
                await self.send_batch_messages(group_id, messages)
            else:
                # å¹³å°ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼Œå›é€€åˆ°å•ç‹¬å‘é€
                logger.info(f"å¹³å° {platform_name} ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼Œå°† {len(messages)} æ¡æ¶ˆæ¯é€ä¸ªå‘é€")
                await self.send_individual_messages(group_id, messages)

        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    async def send_batch_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€æ‰¹é‡åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼ˆä»…æ”¯æŒ aiocqhttp ç­‰å¹³å°ï¼‰"""
        logger.info(f"ä½¿ç”¨åˆå¹¶è½¬å‘å‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        # æ„å»ºåˆå¹¶è½¬å‘èŠ‚ç‚¹
        forward_nodes = []
        for msg in messages:
            content = []
            if msg.get("image_url"):
                content.append(Comp.Image.fromURL(msg["image_url"]))
            content.append(Comp.Plain(msg["message_text"]))

            node = Comp.Node(
                content=content, uin="2659908767", name="åª’ä½“é€šçŸ¥"  # å¯ä»¥é…ç½®åŒ–
            )
            forward_nodes.append(node)

        # å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯
        platform_name = self.config.get("platform_name", "aiocqhttp")
        unified_msg_origin = f"{platform_name}:GroupMessage:{group_id}"
        logger.debug(f"å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼Œunified_msg_origin: {unified_msg_origin}")
        message_chain = MessageChain(chain=forward_nodes)
        await self.context.send_message(unified_msg_origin, message_chain)

        logger.info(f"æˆåŠŸå‘é€ {len(messages)} æ¡åˆå¹¶è½¬å‘æ¶ˆæ¯")

    async def send_individual_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€å•ç‹¬æ¶ˆæ¯ï¼ˆé€‚ç”¨äºæ‰€æœ‰å¹³å°ï¼‰"""
        logger.info(f"é€ä¸ªå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        platform_name = self.config.get("platform_name", "aiocqhttp")
        unified_msg_origin = f"{platform_name}:GroupMessage:{group_id}"
        logger.debug(f"å‘é€å•ç‹¬æ¶ˆæ¯ï¼Œunified_msg_origin: {unified_msg_origin}")

        for msg in messages:
            content = []
            if msg.get("image_url"):
                content.append(Comp.Image.fromURL(msg["image_url"]))
            content.append(Comp.Plain(msg["message_text"]))

            message_chain = MessageChain(chain=content)
            await self.context.send_message(unified_msg_origin, message_chain)

        logger.info(f"æˆåŠŸé€ä¸ªå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

    @filter.command("webhook_status")
    async def webhook_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹WebhookçŠ¶æ€"""
        port = self.config.get("webhook_port", 60071)
        path = self.config.get("webhook_path", "/media-webhook")
        queue_size = len(self.message_queue)
        cache_size = len(self.request_cache)

        platform_name = self.config.get("platform_name", "aiocqhttp")
        supports_forward = self.supports_forward_messages(platform_name)
        force_individual = self.config.get("force_individual_send", False)

        # ç¡®å®šå‘é€ç­–ç•¥
        if force_individual:
            send_strategy = "å¼ºåˆ¶å•ç‹¬å‘é€"
        elif supports_forward:
            send_strategy = f"æ™ºèƒ½å‘é€ï¼ˆæ”¯æŒåˆå¹¶è½¬å‘ï¼‰"
        else:
            send_strategy = f"å•ç‹¬å‘é€ï¼ˆå¹³å°ä¸æ”¯æŒåˆå¹¶è½¬å‘ï¼‰"

        status_text = f"""ğŸ“Š Media Webhook çŠ¶æ€
ğŸŒ æœåŠ¡åœ°å€: http://localhost:{port}{path}
ğŸ¯ ç›®æ ‡ç¾¤ç»„: {self.config.get('group_id', 'æœªé…ç½®')}
ğŸ”— æ¶ˆæ¯å¹³å°: {platform_name}
ğŸ“¤ å‘é€ç­–ç•¥: {send_strategy}
ğŸ”€ åˆå¹¶è½¬å‘æ”¯æŒ: {'âœ…' if supports_forward else 'âŒ'}

ğŸ“‹ é˜Ÿåˆ—æ¶ˆæ¯æ•°: {queue_size}
ğŸ—‚ï¸ ç¼“å­˜è¯·æ±‚æ•°: {cache_size}
âš™ï¸ æ‰¹é‡å‘é€é˜ˆå€¼: {self.config.get('batch_min_size', 3)}
â° å¤„ç†é—´éš”: {self.config.get('batch_interval_seconds', 300)}ç§’"""

        yield event.plain_result(status_text)

    @filter.command("webhook_test")
    async def webhook_test(self, event: AstrMessageEvent, data_source: str = "static", include_image: str = "auto"):
        """æµ‹è¯•WebhookåŠŸèƒ½

        Args:
            data_source: æ•°æ®æº (static/bgm)ï¼Œé»˜è®¤ä¸º static
            include_image: æ˜¯å¦åŒ…å«å›¾ç‰‡æµ‹è¯• (yes/no/auto)ï¼Œé»˜è®¤ä¸º auto
        """
        # æ ¹æ®æ•°æ®æºè·å–æµ‹è¯•æ•°æ®
        if data_source.lower() in ["bgm", "bangumi"]:
            yield event.plain_result("ğŸ”„ æ­£åœ¨ä» BGM.TV è·å–éšæœºå‰§é›†æ•°æ®...")
            test_data = await self.fetch_bgm_data()

            if not test_data:
                yield event.plain_result("âŒ æ— æ³•ä» BGM.TV è·å–æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•æ•°æ®")
                test_data = self.get_default_test_data()
            else:
                yield event.plain_result("âœ… æˆåŠŸè·å– BGM.TV æ•°æ®")
        else:
            test_data = self.get_default_test_data()

        # å¤„ç†å›¾ç‰‡è®¾ç½®
        if include_image.lower() == "auto":
            # å¦‚æœæ˜¯ BGM æ•°æ®ä¸”æœ‰å›¾ç‰‡URLï¼Œåˆ™åŒ…å«å›¾ç‰‡
            include_image = "yes" if (data_source.lower() in ["bgm", "bangumi"] and test_data.get("image_url")) else "no"

        # å¦‚æœæ˜ç¡®ä¸è¦å›¾ç‰‡ï¼Œç§»é™¤å›¾ç‰‡URL
        if include_image.lower() in ["no", "n", "false", "0"]:
            test_data.pop("image_url", None)
        elif include_image.lower() in ["yes", "y", "true", "1"] and not test_data.get("image_url"):
            # å¦‚æœè¦æ±‚å›¾ç‰‡ä½†æ²¡æœ‰å›¾ç‰‡URLï¼Œä½¿ç”¨é»˜è®¤å›¾ç‰‡
            test_data["image_url"] = "https://picsum.photos/300/450"

        message_text = self.generate_message_text(test_data)

        content = []
        image_url = test_data.get("image_url")
        if image_url:
            try:
                content.append(Comp.Image.fromURL(str(image_url)))
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½æµ‹è¯•å›¾ç‰‡: {e}")
                content.append(Comp.Plain(f"[å›¾ç‰‡åŠ è½½å¤±è´¥: {image_url}]\n\n"))
        content.append(Comp.Plain(message_text))

        yield event.chain_result(content)

    def get_default_test_data(self) -> Dict:
        """è·å–é»˜è®¤æµ‹è¯•æ•°æ®"""
        return {
            "item_type": "Episode",
            "series_name": "æµ‹è¯•å‰§é›†",
            "year": "2024",
            "item_name": "æµ‹è¯•é›†åç§°",
            "season_number": 1,
            "episode_number": 1,
            "overview": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‰§æƒ…ç®€ä»‹",
            "runtime": "45åˆ†é’Ÿ",
        }

    @filter.command("webhook_test_simple")
    async def webhook_test_simple(self, event: AstrMessageEvent):
        """ç®€å•æµ‹è¯•WebhookåŠŸèƒ½ï¼ˆä¸åŒ…å«å›¾ç‰‡ï¼‰"""
        test_data = {
            "item_type": "Episode",
            "series_name": "æµ‹è¯•å‰§é›†",
            "year": "2024",
            "item_name": "æµ‹è¯•é›†åç§°",
            "season_number": 1,
            "episode_number": 1,
            "overview": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‰§æƒ…ç®€ä»‹",
            "runtime": "45åˆ†é’Ÿ",
        }

        message_text = self.generate_message_text(test_data)
        yield event.plain_result(message_text)

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        try:
            if self.site:
                await self.site.stop()
            if self.runner:
                await self.runner.cleanup()
            logger.info("Media Webhook æœåŠ¡å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ Webhook æœåŠ¡æ—¶å‡ºé”™: {e}")
