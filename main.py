import asyncio
import hashlib
import html
import json
import time
from typing import Dict, List, Optional

import astrbot.api.message_components as Comp
from aiohttp import web
from aiohttp.web import Request, Response
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.star import Context, Star, register


@register(
    "media_webhook",
    "Assistant",
    "åª’ä½“é€šçŸ¥ Webhook æ’ä»¶",
    "1.0.0",
    "https://github.com/example/astrbot_plugin_media_webhook",
)
class MediaWebhookPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.app = None
        self.runner = None
        self.site = None

        # æ¶ˆæ¯é˜Ÿåˆ—å’Œç¼“å­˜
        self.message_queue: List[Dict] = []
        self.request_cache: Dict[str, float] = {}  # hash -> timestamp

        # åª’ä½“ç±»å‹æ˜ å°„
        self.media_type_map = {
            "Movie": "ç”µå½±",
            "Series": "å‰§é›†",
            "Season": "å‰§å­£",
            "Episode": "å•é›†",
            "Album": "ä¸“è¾‘",
            "Song": "æ­Œæ›²",
            "Video": "è§†é¢‘",
        }
        self.type_emoji_map = {"Season": "ğŸ¬", "Episode": "ğŸ“º", "Default": "ğŸŒŸ"}

        # éªŒè¯é…ç½®
        self.validate_config()

        # å¯åŠ¨HTTPæœåŠ¡å™¨å’Œå®šæ—¶ä»»åŠ¡
        asyncio.create_task(self.start_webhook_server())
        asyncio.create_task(self.start_batch_processor())

    def validate_config(self):
        """éªŒè¯é…ç½®å‚æ•°"""
        port = self.config.get("webhook_port", 60071)
        if not isinstance(port, int) or port < 1 or port > 65535:
            logger.warning(f"æ— æ•ˆçš„ç«¯å£å·: {port}ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 60071")
            self.config["webhook_port"] = 60071

        batch_interval = self.config.get("batch_interval_seconds", 300)
        if not isinstance(batch_interval, int) or batch_interval < 10:
            logger.warning(f"æ‰¹é‡å¤„ç†é—´éš”è¿‡çŸ­: {batch_interval}ç§’ï¼Œè®¾ç½®ä¸ºæœ€å°å€¼ 10ç§’")
            self.config["batch_interval_seconds"] = max(10, batch_interval)

        cache_ttl = self.config.get("cache_ttl_seconds", 300)
        if not isinstance(cache_ttl, int) or cache_ttl < 60:
            logger.warning(f"ç¼“å­˜TTLè¿‡çŸ­: {cache_ttl}ç§’ï¼Œè®¾ç½®ä¸ºæœ€å°å€¼ 60ç§’")
            self.config["cache_ttl_seconds"] = max(60, cache_ttl)

    async def start_webhook_server(self):
        """å¯åŠ¨HTTP WebhookæœåŠ¡å™¨"""
        try:
            self.app = web.Application()
            self.app.router.add_post(
                self.config.get("webhook_path", "/media-webhook"), self.handle_webhook
            )

            self.runner = web.AppRunner(self.app)
            await self.runner.setup()

            port = self.config.get("webhook_port", 60071)
            self.site = web.TCPSite(self.runner, "0.0.0.0", port)
            await self.site.start()

            logger.info(f"Media Webhook æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£: {port}")
            logger.info(
                f"è®¿é—®åœ°å€: http://localhost:{port}{self.config.get('webhook_path', '/media-webhook')}"
            )

        except OSError as e:
            if "Address already in use" in str(e) or "Only one usage" in str(e):
                logger.error(
                    f"ç«¯å£ {self.config.get('webhook_port', 60071)} å·²è¢«å ç”¨ï¼Œè¯·æ›´æ¢ç«¯å£"
                )
            else:
                logger.error(f"ç½‘ç»œé”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"å¯åŠ¨ Webhook æœåŠ¡å™¨å¤±è´¥: {e}")

    async def handle_webhook(self, request: Request) -> Response:
        """å¤„ç†Webhookè¯·æ±‚"""
        try:
            # è§£æè¯·æ±‚ä½“
            body_text = await request.text()
            if not body_text:
                return Response(text="è¯·æ±‚ä½“ä¸ºç©º", status=400)

            media_data = json.loads(body_text)

            # è®¡ç®—è¯·æ±‚å“ˆå¸Œå€¼
            request_hash = self.calculate_body_hash(media_data)

            # æ£€æŸ¥é‡å¤è¯·æ±‚
            if request_hash and self.is_duplicate_request(request_hash):
                logger.warning(f"æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œå·²å¿½ç•¥ã€‚[hash: {request_hash}]")
                return Response(text="é‡å¤è¯·æ±‚å·²è¢«å¿½ç•¥", status=202)

            # ç¼“å­˜è¯·æ±‚å“ˆå¸Œ
            if request_hash:
                cache_ttl = self.config.get("cache_ttl_seconds", 300)
                self.request_cache[request_hash] = time.time() + cache_ttl

            # ç”Ÿæˆæ¶ˆæ¯å†…å®¹
            message_payload = {
                "image_url": media_data.get("image_url", ""),
                "message_text": self.generate_message_text(media_data),
                "timestamp": time.time(),
            }

            # æ·»åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            self.message_queue.append(message_payload)

            logger.info(
                f"æ–° {media_data.get('item_type', 'Unknown')} é€šçŸ¥å·²åŠ å…¥é˜Ÿåˆ—ã€‚[hash: {request_hash}]"
            )
            return Response(text="æ¶ˆæ¯å·²åŠ å…¥é˜Ÿåˆ—", status=200)

        except json.JSONDecodeError:
            logger.error("Webhook è¯·æ±‚ä½“è§£æå¤±è´¥: æ— æ•ˆçš„JSONæ ¼å¼")
            return Response(text="æ— æ•ˆçš„JSONæ ¼å¼", status=400)
        except Exception as e:
            logger.error(f"Webhook å¤„ç†å‡ºé”™: {e}")
            return Response(text="å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯", status=500)

    def calculate_body_hash(self, body: Dict) -> Optional[str]:
        """è®¡ç®—è¯·æ±‚ä½“å“ˆå¸Œå€¼"""
        try:
            body_for_hash = body.copy()
            body_for_hash.pop("image_url", None)  # æ’é™¤å›¾ç‰‡URL
            body_string = json.dumps(body_for_hash, sort_keys=True)
            return hashlib.md5(body_string.encode()).hexdigest()
        except Exception as e:
            logger.error(f"MD5 å“ˆå¸Œè®¡ç®—å¤±è´¥: {e}")
            return None

    def is_duplicate_request(self, request_hash: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚"""
        current_time = time.time()

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        expired_keys = [k for k, v in self.request_cache.items() if v < current_time]
        for key in expired_keys:
            del self.request_cache[key]

        return request_hash in self.request_cache

    def decode_html_entities(self, text: str) -> str:
        """è§£ç HTMLå®ä½“"""
        if not text:
            return ""
        return html.unescape(text)

    def generate_main_section(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯ä¸»è¦éƒ¨åˆ†"""
        sections = []
        series_name = data.get("series_name", "")
        year = data.get("year", "")
        item_type = data.get("item_type", "")
        item_name = data.get("item_name", "")
        season_number = data.get("season_number", "")
        episode_number = data.get("episode_number", "")

        if series_name:
            year_text = f" ({year})" if year else ""
            sections.append(f"å‰§é›†åç§°: {series_name}{year_text}")

        if item_type == "Season":
            if item_name:
                sections.append(f"å­£åç§°: {item_name}")
            if season_number:
                sections.append(f"å­£å·: {season_number}")
        elif item_type == "Episode":
            if season_number and episode_number:
                s_num = str(season_number).zfill(2)
                e_num = str(episode_number).zfill(2)
                sections.append(f"é›†å·: S{s_num}E{e_num}")
            if item_name:
                sections.append(f"é›†åç§°: {item_name}")
        else:
            if item_name:
                sections.append(f"åç§°: {item_name}")
            if year:
                sections.append(f"å¹´ä»½: {year}")

        return "\n".join(sections)

    def generate_message_text(self, data: Dict) -> str:
        """ç”Ÿæˆæ¶ˆæ¯æ–‡æœ¬"""
        item_type = data.get("item_type", "")
        cn_type = self.media_type_map.get(item_type, item_type)
        emoji = self.type_emoji_map.get(item_type, self.type_emoji_map["Default"])

        message_parts = [f"{emoji} æ–°{cn_type}ä¸Šçº¿", self.generate_main_section(data)]

        overview = data.get("overview", "")
        if overview:
            decoded_overview = self.decode_html_entities(overview)
            message_parts.append(f"\nå‰§æƒ…ç®€ä»‹:\n{decoded_overview}")

        runtime = data.get("runtime", "")
        if runtime:
            message_parts.append(f"\næ—¶é•¿: {runtime}")

        return "\n\n".join(message_parts)

    async def start_batch_processor(self):
        """å¯åŠ¨æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        while True:
            try:
                interval = self.config.get("batch_interval_seconds", 300)
                await asyncio.sleep(interval)
                await self.process_message_queue()
            except Exception as e:
                logger.error(f"æ‰¹é‡å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")

    async def process_message_queue(self):
        """å¤„ç†æ¶ˆæ¯é˜Ÿåˆ—"""
        if not self.message_queue:
            return

        group_id = self.config.get("group_id", "")
        if not group_id:
            logger.warning("æœªé…ç½®ç¾¤ç»„IDï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return

        messages = self.message_queue.copy()
        self.message_queue.clear()

        logger.info(f"ä»é˜Ÿåˆ—ä¸­å–å‡º {len(messages)} æ¡å¾…å‘æ¶ˆæ¯")

        try:
            batch_min_size = self.config.get("batch_min_size", 3)

            if len(messages) >= batch_min_size:
                await self.send_batch_messages(group_id, messages)
            else:
                await self.send_individual_messages(group_id, messages)

        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    async def send_batch_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€æ‰¹é‡åˆå¹¶è½¬å‘æ¶ˆæ¯"""
        logger.info(f"æ¶ˆæ¯æ•°é‡è¾¾åˆ° {len(messages)} æ¡ï¼Œå‡†å¤‡åˆå¹¶å‘é€")

        # æ„å»ºåˆå¹¶è½¬å‘èŠ‚ç‚¹
        forward_nodes = []
        for msg in messages:
            content = []
            if msg.get("image_url"):
                content.append(Comp.Image.fromURL(msg["image_url"]))
            content.append(Comp.Plain(msg["message_text"]))

            node = Comp.Node(
                uin="2659908767", name="åª’ä½“é€šçŸ¥", content=content  # å¯ä»¥é…ç½®åŒ–
            )
            forward_nodes.append(node)

        # å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯
        unified_msg_origin = f"group_{group_id}"
        message_chain = MessageChain(forward_nodes)
        await self.context.send_message(unified_msg_origin, message_chain)

        logger.info(f"æˆåŠŸå‘é€ {len(messages)} æ¡åˆå¹¶æ¶ˆæ¯")

    async def send_individual_messages(self, group_id: str, messages: List[Dict]):
        """å‘é€å•ç‹¬æ¶ˆæ¯"""
        logger.info(f"æ¶ˆæ¯æ•°é‡ä¸è¶³æ‰¹é‡å‘é€æ¡ä»¶ï¼Œå‡†å¤‡å•ç‹¬å‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        unified_msg_origin = f"group_{group_id}"

        for msg in messages:
            content = []
            if msg.get("image_url"):
                content.append(Comp.Image.fromURL(msg["image_url"]))
            content.append(Comp.Plain(msg["message_text"]))

            message_chain = MessageChain(content)
            await self.context.send_message(unified_msg_origin, message_chain)

        logger.info(f"æˆåŠŸå‘é€ {len(messages)} æ¡å•ç‹¬æ¶ˆæ¯")

    @filter.command("webhook_status")
    async def webhook_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹WebhookçŠ¶æ€"""
        port = self.config.get("webhook_port", 60071)
        path = self.config.get("webhook_path", "/media-webhook")
        queue_size = len(self.message_queue)
        cache_size = len(self.request_cache)

        status_text = f"""ğŸ“Š Media Webhook çŠ¶æ€
ğŸŒ æœåŠ¡åœ°å€: http://localhost:{port}{path}
ğŸ“‹ é˜Ÿåˆ—æ¶ˆæ¯æ•°: {queue_size}
ğŸ—‚ï¸ ç¼“å­˜è¯·æ±‚æ•°: {cache_size}
âš™ï¸ æ‰¹é‡å‘é€é˜ˆå€¼: {self.config.get('batch_min_size', 3)}
â° å¤„ç†é—´éš”: {self.config.get('batch_interval_seconds', 300)}ç§’"""

        yield event.plain_result(status_text)

    @filter.command("webhook_test")
    async def webhook_test(self, event: AstrMessageEvent):
        """æµ‹è¯•WebhookåŠŸèƒ½"""
        test_data = {
            "item_type": "Episode",
            "series_name": "æµ‹è¯•å‰§é›†",
            "year": "2024",
            "item_name": "æµ‹è¯•é›†åç§°",
            "season_number": 1,
            "episode_number": 1,
            "overview": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‰§æƒ…ç®€ä»‹",
            "runtime": "45åˆ†é’Ÿ",
            "image_url": "https://via.placeholder.com/300x450/0066cc/ffffff?text=Test+Media",
        }

        message_text = self.generate_message_text(test_data)

        content = []
        if test_data.get("image_url"):
            content.append(Comp.Image.fromURL(test_data["image_url"]))
        content.append(Comp.Plain(message_text))

        yield event.chain_result(content)

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        try:
            if self.site:
                await self.site.stop()
            if self.runner:
                await self.runner.cleanup()
            logger.info("Media Webhook æœåŠ¡å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢ Webhook æœåŠ¡æ—¶å‡ºé”™: {e}")
